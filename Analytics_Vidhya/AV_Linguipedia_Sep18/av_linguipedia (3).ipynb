{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import fasttext\n",
    "import nltk\n",
    "from sklearn.metrics import log_loss\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tag import pos_tag\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from numpy.random import random, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_2kmZucJ.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  7922  currently shitting my fucking pants. #apple #i...\n",
       "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  7924  My ipod is officially dead. I lost all my pict...\n",
       "4  7925  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_oJQbWVk.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['label']=np.nan\n",
    "train_test=train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2    0.0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3    0.0  We love this! Would you go? #talk #makememorie...\n",
       "3   4    0.0  I'm wired I know I'm George I was made that wa...\n",
       "4   5    1.0  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_split=[re.split('\\W', i) for i in train_test['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  'fingerprint',\n",
       "  '',\n",
       "  'Pregnancy',\n",
       "  'Test',\n",
       "  'https',\n",
       "  '',\n",
       "  '',\n",
       "  'goo',\n",
       "  'gl',\n",
       "  'h1MfQV',\n",
       "  '',\n",
       "  'android',\n",
       "  '',\n",
       "  'apps',\n",
       "  '',\n",
       "  'beautiful',\n",
       "  '',\n",
       "  'cute',\n",
       "  '',\n",
       "  'health',\n",
       "  '',\n",
       "  'igers',\n",
       "  '',\n",
       "  'iphoneonly',\n",
       "  '',\n",
       "  'iphonesia',\n",
       "  '',\n",
       "  'iphone'],\n",
       " ['Finally',\n",
       "  'a',\n",
       "  'transparant',\n",
       "  'silicon',\n",
       "  'case',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Thanks',\n",
       "  'to',\n",
       "  'my',\n",
       "  'uncle',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'yay',\n",
       "  '',\n",
       "  'Sony',\n",
       "  '',\n",
       "  'Xperia',\n",
       "  '',\n",
       "  'S',\n",
       "  '',\n",
       "  'sonyexperias',\n",
       "  '',\n",
       "  'http',\n",
       "  '',\n",
       "  '',\n",
       "  'instagram',\n",
       "  'com',\n",
       "  'p',\n",
       "  'YGEt5JC6JM',\n",
       "  '']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_split[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wordvec\n",
    "model_w2v = word2vec.Word2Vec(sentences_split, size=40,min_count =1, window=3, workers =-1,sample=1e-5)\n",
    "features_sent = np.zeros(shape=(0,40))\n",
    "for i in sentences_split:\n",
    "\tsu=np.zeros(shape=(40))\n",
    "\tnum_words = 0\n",
    "\tfor j in i:\n",
    "\t\tk=np.array(model_w2v.wv[j])\n",
    "\t\tsu=su+k\n",
    "\t\t#print(su)\n",
    "\t\tnum_words = num_words + 1\n",
    "\tfeatures_sent=np.vstack([features_sent, su/num_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28142569e-03,  9.94422021e-04,  7.38821822e-03, ...,\n",
       "        -2.12370462e-03, -6.64981878e-03, -1.86545554e-03],\n",
       "       [-1.83103364e-03,  2.13772872e-03,  5.61906230e-03, ...,\n",
       "        -3.72773241e-03, -4.02820242e-03, -1.35200242e-03],\n",
       "       [-2.51752905e-03,  1.56261013e-03,  6.21849537e-03, ...,\n",
       "        -2.55547025e-03, -3.44236642e-03, -2.30906241e-03],\n",
       "       ...,\n",
       "       [ 8.87125972e-05, -9.37895882e-04,  1.36522539e-03, ...,\n",
       "        -4.08037656e-04,  5.40530949e-04, -7.71504710e-05],\n",
       "       [ 1.01264288e-03,  2.48966200e-03,  3.04591666e-04, ...,\n",
       "         3.23849299e-03, -3.16436909e-03, -8.33710760e-04],\n",
       "       [-3.36783765e-03,  1.60618845e-03,  5.97821399e-03, ...,\n",
       "        -8.39755151e-04, -5.25280466e-03, -7.06801696e-04]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tfidf\n",
    "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=.01, use_idf=True, smooth_idf=False, sublinear_tf=True)\n",
    "sklearn_representation = sklearn_tfidf.fit(train_test['tweet'])\n",
    "train_test_tfidf=pd.DataFrame(sklearn_tfidf.transform(train_test['tweet']).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1    2    3    4    5         6         7    8    9   ...   219  \\\n",
       "0  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0 ...   0.0   \n",
       "1  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0 ...   0.0   \n",
       "2  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0 ...   0.0   \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.0  0.268453  0.000000  0.0  0.0 ...   0.0   \n",
       "4  0.0  0.374102  0.0  0.0  0.0  0.0  0.000000  0.360554  0.0  0.0 ...   0.0   \n",
       "\n",
       "   220  221  222  223       224  225  226       227  228  \n",
       "0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.362376  0.0  0.0  0.236609  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test['tweet'].to_csv('train_test_text.csv',index=False)\n",
    "model_sk = fasttext.skipgram('train_test_text.csv', 'model_sk',dim=40)\n",
    "features_sent_ft = np.zeros(shape=(0,40))\n",
    "for i in sentences_split:\n",
    "\tsu=np.zeros(shape=(40))\n",
    "\tnum_words = 0\n",
    "\tfor j in i:\n",
    "\t\tk=np.array(model_sk[j])\n",
    "\t\tsu=su+k\n",
    "\t\t#print(su)\n",
    "\t\tnum_words = num_words + 1\n",
    "\tfeatures_sent_ft=np.vstack([features_sent_ft, su/num_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.001281  0.000994  0.007388 -0.000455  0.003235  0.004266  0.002389   \n",
       "1 -0.001831  0.002138  0.005619 -0.001370  0.004186  0.004372  0.002200   \n",
       "2 -0.002518  0.001563  0.006218 -0.002845  0.004764  0.005700 -0.000363   \n",
       "3 -0.002011  0.000873  0.003132  0.000659  0.003971  0.004942  0.001594   \n",
       "4 -0.001778 -0.000013  0.002864  0.000301  0.000116  0.001665  0.000997   \n",
       "\n",
       "        7         8         9   ...   219  220  221  222  223       224  225  \\\n",
       "0 -0.002703  0.001234  0.000349 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "1 -0.003409  0.000589  0.001206 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "2 -0.003761 -0.000141  0.002367 ...   0.0  0.0  0.0  0.0  0.0  0.362376  0.0   \n",
       "3 -0.003140  0.001512  0.000241 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "4 -0.001283  0.001022  0.001967 ...   0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "\n",
       "   226       227  228  \n",
       "0  0.0  0.000000  0.0  \n",
       "1  0.0  0.000000  0.0  \n",
       "2  0.0  0.236609  0.0  \n",
       "3  0.0  0.000000  0.0  \n",
       "4  0.0  0.000000  0.0  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_features=pd.concat([pd.DataFrame(features_sent),pd.DataFrame(features_sent_ft),train_test_tfidf],axis=1)\n",
    "train_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'taggers/averaged_perceptron_tagger/averaged_perceptron\n  _tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fde4600e96f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_of_non_english_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meng_wds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'taggers/averaged_perceptron_tagger/averaged_perceptron\n  _tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "train_test['num_of_unique_punctuations'] = train_test['tweet'].apply(lambda x : len(set(x).intersection(set(string.punctuation))))\n",
    "d_us = enchant.Dict(\"en_US\")\n",
    "train_test['num_of_american_spelling_words'] = train_test['tweet'].apply(lambda x: sum([1 for wd in word_tokenize(str(x)) if d_us.check(wd)]))\n",
    "d_gb = enchant.Dict(\"en_GB\")\n",
    "train_test['num_of_greatbritain_spelling_words'] = train_test['tweet'].apply(lambda x: sum([1 for wd in word_tokenize(str(x)) if d_gb.check(wd)]))\n",
    "stp_wds = set(stopwords.words('english'))\n",
    "train_test['num_stopwords'] = train_test['tweet'].apply(lambda x: len(stp_wds.intersection(word_tokenize(str(x)))))\n",
    "punct_list = list(set(string.punctuation))\n",
    "train_test['avg_no_words'] = train_test['tweet'].apply(lambda x: np.nanmean([len([kk for kk in word_tokenize(stn) if kk not in punct_list]) for stn in sent_tokenize(str(x))]))\n",
    "eng_wds = words.words() + list(set(string.punctuation))\n",
    "train_test['num_of_non_english_words'] = train_test['tweet'].apply(lambda x: len([i for i in word_tokenize(str(x)) if i not in eng_wds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for snt in train_test['tweet']:\n",
    "\tdi = Counter([j for i,j in pos_tag(word_tokenize(snt))])\n",
    "\tfor a in di.keys():\n",
    "\t\ttrain_test_features[str(a)] = di[a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in ['num_of_unique_punctuations', 'num_of_american_spelling_words', 'num_of_greatbritain_spelling_words', 'num_stopwords', 'avg_no_words', 'num_of_non_english_words']:\n",
    "\ttrain_test_features[i] = train_test[i].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>num_of_unique_punctuations</th>\n",
       "      <th>num_of_american_spelling_words</th>\n",
       "      <th>num_of_greatbritain_spelling_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>avg_no_words</th>\n",
       "      <th>num_of_non_english_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.001281  0.000994  0.007388 -0.000455  0.003235  0.004266  0.002389   \n",
       "1 -0.001831  0.002138  0.005619 -0.001370  0.004186  0.004372  0.002200   \n",
       "2 -0.002518  0.001563  0.006218 -0.002845  0.004764  0.005700 -0.000363   \n",
       "3 -0.002011  0.000873  0.003132  0.000659  0.003971  0.004942  0.001594   \n",
       "4 -0.001778 -0.000013  0.002864  0.000301  0.000116  0.001665  0.000997   \n",
       "\n",
       "          7         8         9            ...             225  226       227  \\\n",
       "0 -0.002703  0.001234  0.000349            ...             0.0  0.0  0.000000   \n",
       "1 -0.003409  0.000589  0.001206            ...             0.0  0.0  0.000000   \n",
       "2 -0.003761 -0.000141  0.002367            ...             0.0  0.0  0.236609   \n",
       "3 -0.003140  0.001512  0.000241            ...             0.0  0.0  0.000000   \n",
       "4 -0.001283  0.001022  0.001967            ...             0.0  0.0  0.000000   \n",
       "\n",
       "   228  num_of_unique_punctuations  num_of_american_spelling_words  \\\n",
       "0  0.0                           4                               8   \n",
       "1  0.0                           6                              10   \n",
       "2  0.0                           6                              11   \n",
       "3  0.0                           8                              13   \n",
       "4  0.0                           4                              22   \n",
       "\n",
       "   num_of_greatbritain_spelling_words  num_stopwords  avg_no_words  \\\n",
       "0                                   8              0     14.000000   \n",
       "1                                  10              3     17.000000   \n",
       "2                                  11              2      5.666667   \n",
       "3                                  13              2     19.000000   \n",
       "4                                  22              8     12.000000   \n",
       "\n",
       "   num_of_non_english_words  \n",
       "0                         9  \n",
       "1                        10  \n",
       "2                         9  \n",
       "3                         6  \n",
       "4                         4  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features.to_csv(\"train_test_features.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 'num_of_unique_punctuations',\n",
       " 'num_of_american_spelling_words',\n",
       " 'num_of_greatbritain_spelling_words',\n",
       " 'num_stopwords',\n",
       " 'avg_no_words',\n",
       " 'num_of_non_english_words']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features.columns = ['w2v' + str(i) for i in range(40)] + ['ft' + str(i) for i in range(40)] + ['tfidf' + str(i) for i in range(229)] + ['num_of_unique_punctuations', 'num_of_american_spelling_words', 'num_of_greatbritain_spelling_words', 'num_stopwords', 'avg_no_words', 'num_of_non_english_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using text blob sentiment analysis as a feature\n",
    "train_test_features['textblob_polarity'] = list(train_test['tweet'].apply(lambda x : TextBlob(x).sentiment.polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features['textblob_subjectivity'] = list(train_test['tweet'].apply(lambda x : TextBlob(x).sentiment.subjectivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v0</th>\n",
       "      <th>w2v1</th>\n",
       "      <th>w2v2</th>\n",
       "      <th>w2v3</th>\n",
       "      <th>w2v4</th>\n",
       "      <th>w2v5</th>\n",
       "      <th>w2v6</th>\n",
       "      <th>w2v7</th>\n",
       "      <th>w2v8</th>\n",
       "      <th>w2v9</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf227</th>\n",
       "      <th>tfidf228</th>\n",
       "      <th>num_of_unique_punctuations</th>\n",
       "      <th>num_of_american_spelling_words</th>\n",
       "      <th>num_of_greatbritain_spelling_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>avg_no_words</th>\n",
       "      <th>num_of_non_english_words</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w2v0      w2v1      w2v2      w2v3      w2v4      w2v5      w2v6  \\\n",
       "0 -0.001281  0.000994  0.007388 -0.000455  0.003235  0.004266  0.002389   \n",
       "1 -0.001831  0.002138  0.005619 -0.001370  0.004186  0.004372  0.002200   \n",
       "2 -0.002518  0.001563  0.006218 -0.002845  0.004764  0.005700 -0.000363   \n",
       "3 -0.002011  0.000873  0.003132  0.000659  0.003971  0.004942  0.001594   \n",
       "4 -0.001778 -0.000013  0.002864  0.000301  0.000116  0.001665  0.000997   \n",
       "\n",
       "       w2v7      w2v8      w2v9          ...            tfidf227  tfidf228  \\\n",
       "0 -0.002703  0.001234  0.000349          ...            0.000000       0.0   \n",
       "1 -0.003409  0.000589  0.001206          ...            0.000000       0.0   \n",
       "2 -0.003761 -0.000141  0.002367          ...            0.236609       0.0   \n",
       "3 -0.003140  0.001512  0.000241          ...            0.000000       0.0   \n",
       "4 -0.001283  0.001022  0.001967          ...            0.000000       0.0   \n",
       "\n",
       "   num_of_unique_punctuations  num_of_american_spelling_words  \\\n",
       "0                           4                               8   \n",
       "1                           6                              10   \n",
       "2                           6                              11   \n",
       "3                           8                              13   \n",
       "4                           4                              22   \n",
       "\n",
       "   num_of_greatbritain_spelling_words  num_stopwords  avg_no_words  \\\n",
       "0                                   8              0     14.000000   \n",
       "1                                  10              3     17.000000   \n",
       "2                                  11              2      5.666667   \n",
       "3                                  13              2     19.000000   \n",
       "4                                  22              8     12.000000   \n",
       "\n",
       "   num_of_non_english_words  textblob_polarity  textblob_subjectivity  \n",
       "0                         9           0.675000               1.000000  \n",
       "1                        10           0.233333               0.733333  \n",
       "2                         9           0.625000               0.600000  \n",
       "3                         6           0.375000               1.000000  \n",
       "4                         4          -0.125000               0.950000  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_words = ['a+','abound','abounds','abundance','abundant','accessable','accessible','acclaim','acclaimed','acclamation','accolade','accolades','accommodative','accomodative','accomplish','accomplished','accomplishment','accomplishments','accurate','accurately','achievable','achievement','achievements','achievible','acumen','adaptable','adaptive','adequate','adjustable','admirable','admirably','admiration','admire','admirer','admiring','admiringly','adorable','adore','adored','adorer','adoring','adoringly','adroit','adroitly','adulate','adulation','adulatory','advanced','advantage','advantageous','advantageously','advantages','adventuresome','adventurous','advocate','advocated','advocates','affability','affable','affably','affectation','affection','affectionate','affinity','affirm','affirmation','affirmative','affluence','affluent','afford','affordable','affordably','afordable','agile','agilely','agility','agreeable','agreeableness','agreeably','all-around','alluring','alluringly','altruistic','altruistically','amaze','amazed','amazement','amazes','amazing','amazingly','ambitious','ambitiously','ameliorate','amenable','amenity','amiability','amiabily','amiable','amicability','amicable','amicably','amity','ample','amply','amuse','amusing','amusingly','angel','angelic','apotheosis','appeal','appealing','applaud','appreciable','appreciate','appreciated','appreciates','appreciative','appreciatively','appropriate','approval','approve','ardent','ardently','ardor','articulate','aspiration','aspirations','aspire','assurance','assurances','assure','assuredly','assuring','astonish','astonished','astonishing','astonishingly','astonishment','astound','astounded','astounding','astoundingly','astutely','attentive','attraction','attractive','attractively','attune','audible','audibly','auspicious','authentic','authoritative','autonomous','available','aver','avid','avidly','award','awarded','awards','awe','awed','awesome','awesomely','awesomeness','awestruck','awsome','backbone','balanced','bargain','beauteous','beautiful','beautifullly','beautifully','beautify','beauty','beckon','beckoned','beckoning','beckons','believable','believeable','beloved','benefactor','beneficent','beneficial','beneficially','beneficiary','benefit','benefits','benevolence','benevolent','benifits','best','best-known','best-performing','best-selling','better','better-known','better-than-expected','beutifully','blameless','bless','blessing','bliss','blissful','blissfully','blithe','blockbuster','bloom','blossom','bolster','bonny','bonus','bonuses','boom','booming','boost','boundless','bountiful','brainiest','brainy','brand-new','brave','bravery','bravo','breakthrough','breakthroughs','breathlessness','breathtaking','breathtakingly','breeze','bright','brighten','brighter','brightest','brilliance','brilliances','brilliant','brilliantly','brisk','brotherly','bullish','buoyant','cajole','calm','calming','calmness','capability','capable','capably','captivate','captivating','carefree','cashback','cashbacks','catchy','celebrate','celebrated','celebration','celebratory','champ','champion','charisma','charismatic','charitable','charm','charming','charmingly','chaste','cheaper','cheapest','cheer','cheerful','cheery','cherish','cherished','cherub','chic','chivalrous','chivalry','civility','civilize','clarity','classic','classy','clean','cleaner','cleanest','cleanliness','cleanly','clear','clear-cut','cleared','clearer','clearly','clears','clever','cleverly','cohere','coherence','coherent','cohesive','colorful','comely','comfort','comfortable','comfortably','comforting','comfy','commend','commendable','commendably','commitment','commodious','compact','compactly','compassion','compassionate','compatible','competitive','complement','complementary','complemented','complements','compliant','compliment','complimentary','comprehensive','conciliate','conciliatory','concise','confidence','confident','congenial','congratulate','congratulation','congratulations','congratulatory','conscientious','considerate','consistent','consistently','constructive','consummate','contentment','continuity','contrasty','contribution','convenience','convenient','conveniently','convience','convienient','convient','convincing','convincingly','cool','coolest','cooperative','cooperatively','cornerstone','correct','correctly','cost-effective','cost-saving','counter-attack','counter-attacks','courage','courageous','courageously','courageousness','courteous','courtly','covenant','cozy','creative','credence','credible','crisp','crisper','cure','cure-all','cushy','cute','cuteness','danke','danken','daring','daringly','darling','dashing','dauntless','dawn','dazzle','dazzled','dazzling','dead-cheap','dead-on','decency','decent','decisive','decisiveness','dedicated','defeat','defeated','defeating','defeats','defender','deference','deft','deginified','delectable','delicacy','delicate','delicious','delight','delighted','delightful','delightfully','delightfulness','dependable','dependably','deservedly','deserving','desirable','desiring','desirous','destiny','detachable','devout','dexterous','dexterously','dextrous','dignified','dignify','dignity','diligence','diligent','diligently','diplomatic','dirt-cheap','distinction','distinctive','distinguished','diversified','divine','divinely','dominate','dominated','dominates','dote','dotingly','doubtless','dreamland','dumbfounded','dumbfounding','dummy-proof','durable','dynamic','eager','eagerly','eagerness','earnest','earnestly','earnestness','ease','eased','eases','easier','easiest','easiness','easing','easy','easy-to-use','easygoing','ebullience','ebullient','ebulliently','ecenomical','economical','ecstasies','ecstasy','ecstatic','ecstatically','edify','educated','effective','effectively','effectiveness','effectual','efficacious','efficient','efficiently','effortless','effortlessly','effusion','effusive','effusively','effusiveness','elan','elate','elated','elatedly','elation','electrify','elegance','elegant','elegantly','elevate','elite','eloquence','eloquent','eloquently','embolden','eminence','eminent','empathize','empathy','empower','empowerment','enchant','enchanted','enchanting','enchantingly','encourage','encouragement','encouraging','encouragingly','endear','endearing','endorse','endorsed','endorsement','endorses','endorsing','energetic','energize','energy-efficient','energy-saving','engaging','engrossing','enhance','enhanced','enhancement','enhances','enjoy','enjoyable','enjoyably','enjoyed','enjoying','enjoyment','enjoys','enlighten','enlightenment','enliven','ennoble','enough','enrapt','enrapture','enraptured','enrich','enrichment','enterprising','entertain','entertaining','entertains','enthral','enthrall','enthralled','enthuse','enthusiasm','enthusiast','enthusiastic','enthusiastically','entice','enticed','enticing','enticingly','entranced','entrancing','entrust','enviable','enviably','envious','enviously','enviousness','envy','equitable','ergonomical','err-free','erudite','ethical','eulogize','euphoria','euphoric','euphorically','evaluative','evenly','eventful','everlasting','evocative','exalt','exaltation','exalted','exaltedly','exalting','exaltingly','examplar','examplary','excallent','exceed','exceeded','exceeding','exceedingly','exceeds','excel','exceled','excelent','excellant','excelled','excellence','excellency','excellent','excellently','excels','exceptional','exceptionally','excite','excited','excitedly','excitedness','excitement','excites','exciting','excitingly','exellent','exemplar','exemplary','exhilarate','exhilarating','exhilaratingly','exhilaration','exonerate','expansive','expeditiously','expertly','exquisite','exquisitely','extol','extoll','extraordinarily','extraordinary','exuberance','exuberant','exuberantly','exult','exultant','exultation','exultingly','eye-catch','eye-catching','eyecatch','eyecatching','fabulous','fabulously','facilitate','fair','fairly','fairness','faith','faithful','faithfully','faithfulness','fame','famed','famous','famously','fancier','fancinating','fancy','fanfare','fans','fantastic','fantastically','fascinate','fascinating','fascinatingly','fascination','fashionable','fashionably','fast','fast-growing','fast-paced','faster','fastest','fastest-growing','faultless','fav','fave','favor','favorable','favored','favorite','favorited','favour','fearless','fearlessly','feasible','feasibly','feat','feature-rich','fecilitous','feisty','felicitate','felicitous','felicity','fertile','fervent','fervently','fervid','fervidly','fervor','festive','fidelity','fiery','fine','fine-looking','finely','finer','finest','firmer','first-class','first-in-class','first-rate','flashy','flatter','flattering','flatteringly','flawless','flawlessly','flexibility','flexible','flourish','flourishing','fluent','flutter','fond','fondly','fondness','foolproof','foremost','foresight','formidable','fortitude','fortuitous','fortuitously','fortunate','fortunately','fortune','fragrant','free','freed','freedom','freedoms','fresh','fresher','freshest','friendliness','friendly','frolic','frugal','fruitful','ftw','fulfillment','fun','futurestic','futuristic','gaiety','gaily','gain','gained','gainful','gainfully','gaining','gains','gallant','gallantly','galore','geekier','geeky','gem','gems','generosity','generous','generously','genial','genius','gentle','gentlest','genuine','gifted','glad','gladden','gladly','gladness','glamorous','glee','gleeful','gleefully','glimmer','glimmering','glisten','glistening','glitter','glitz','glorify','glorious','gloriously','glory','glow','glowing','glowingly','god-given','god-send','godlike','godsend','gold','golden','good','goodly','goodness','goodwill','goood','gooood','gorgeous','gorgeously','grace','graceful','gracefully','gracious','graciously','graciousness','grand','grandeur','grateful','gratefully','gratification','gratified','gratifies','gratify','gratifying','gratifyingly','gratitude','great','greatest','greatness','grin','groundbreaking','guarantee','guidance','guiltless','gumption','gush','gusto','gutsy',\n",
    "                  'hail','halcyon','hale','hallmark','hallmarks','hallowed','handier','handily','hands-down','handsome','handsomely','handy','happier','happily','happiness','happy','hard-working','hardier','hardy','harmless','harmonious','harmoniously','harmonize','harmony','headway','heal','healthful','healthy','hearten','heartening','heartfelt','heartily','heartwarming','heaven','heavenly','helped','helpful','helping','hero','heroic','heroically','heroine','heroize','heros','high-quality','high-spirited','hilarious','holy','homage','honest','honesty','honor','honorable','honored','honoring','hooray','hopeful','hospitable','hot','hotcake','hotcakes','hottest','hug','humane','humble','humility','humor','humorous','humorously','humour','humourous','ideal','idealize','ideally','idol','idolize','idolized','idyllic','illuminate','illuminati','illuminating','illumine','illustrious','ilu','imaculate','imaginative','immaculate','immaculately','immense','impartial','impartiality','impartially','impassioned','impeccable','impeccably','important','impress','impressed','impresses','impressive','impressively','impressiveness','improve','improved','improvement','improvements','improves','improving','incredible','incredibly','indebted','individualized','indulgence','indulgent','industrious','inestimable','inestimably','inexpensive','infallibility','infallible','infallibly','influential','ingenious','ingeniously','ingenuity','ingenuous','ingenuously','innocuous','innovation','innovative','inpressed','insightful','insightfully','inspiration','inspirational','inspire','inspiring','instantly','instructive','instrumental','integral','integrated','intelligence','intelligent','intelligible','interesting','interests','intimacy','intimate','intricate','intrigue','intriguing','intriguingly','intuitive','invaluable','invaluablely','inventive','invigorate','invigorating','invincibility','invincible','inviolable','inviolate','invulnerable','irreplaceable','irreproachable','irresistible','irresistibly','issue-free','jaw-droping','jaw-dropping','jollify','jolly','jovial','joy','joyful','joyfully','joyous','joyously','jubilant','jubilantly','jubilate','jubilation','jubiliant','judicious','justly','keen','keenly','keenness','kid-friendly','kindliness','kindly','kindness','knowledgeable','kudos','large-capacity','laud','laudable','laudably','lavish','lavishly','law-abiding','lawful','lawfully','lead','leading','leads','lean','led','legendary','leverage','levity','liberate','liberation','liberty','lifesaver','light-hearted','lighter','likable','like','liked','likes','liking','lionhearted','lively','logical','long-lasting','lovable','lovably','love','loved','loveliness','lovely','lover','loves','loving','low-cost','low-price','low-priced','low-risk','lower-priced','loyal','loyalty','lucid','lucidly','luck','luckier','luckiest','luckiness','lucky','lucrative','luminous','lush','luster','lustrous','luxuriant','luxuriate','luxurious','luxuriously','luxury','lyrical','magic','magical','magnanimous','magnanimously','magnificence','magnificent','magnificently','majestic','majesty','manageable','maneuverable','marvel','marveled','marvelled','marvellous','marvelous','marvelously','marvelousness','marvels','master','masterful','masterfully','masterpiece','masterpieces','masters','mastery','matchless','mature','maturely','maturity','meaningful','memorable','merciful','mercifully','mercy','merit','meritorious','merrily','merriment','merriness','merry','mesmerize','mesmerized','mesmerizes','mesmerizing','mesmerizingly','meticulous','meticulously','mightily','mighty','mind-blowing','miracle','miracles','miraculous','miraculously','miraculousness','modern','modest','modesty','momentous','monumental','monumentally','morality','motivated','multi-purpose','navigable','neat','neatest','neatly','nice','nicely','nicer','nicest','nifty','nimble','noble','nobly','noiseless','non-violence','non-violent','notably','noteworthy','nourish','nourishing','nourishment','novelty','nurturing','oasis','obsession','obsessions','obtainable','openly','openness','optimal','optimism','optimistic','opulent','orderly','originality','outdo','outdone','outperform','outperformed','outperforming','outperforms','outshine','outshone','outsmart','outstanding','outstandingly','outstrip','outwit','ovation','overjoyed','overtake','overtaken','overtakes','overtaking','overtook','overture','pain-free','painless','painlessly','palatial','pamper','pampered','pamperedly','pamperedness','pampers','panoramic','paradise','paramount','pardon','passion','passionate','passionately','patience','patient','patiently','patriot','patriotic','peace','peaceable','peaceful','peacefully','peacekeepers','peach','peerless','pep','pepped','pepping','peppy','peps','perfect','perfection','perfectly','permissible','perseverance','persevere','personages','personalized','phenomenal','phenomenally','picturesque','piety','pinnacle','playful','playfully','pleasant','pleasantly','pleased','pleases','pleasing','pleasingly','pleasurable','pleasurably','pleasure','plentiful','pluses','plush','plusses','poetic','poeticize','poignant','poise','poised','polished','polite','politeness','popular','portable','posh','positive','positively','positives','powerful','powerfully','praise','praiseworthy','praising','pre-eminent','precious','precise','precisely','preeminent','prefer','preferable','preferably','prefered','preferes','preferring','prefers','premier','prestige','prestigious','prettily','pretty','priceless','pride','principled','privilege','privileged','prize','proactive','problem-free','problem-solver','prodigious','prodigiously','prodigy','productive','productively','proficient','proficiently','profound','profoundly','profuse','profusion','progress','progressive','prolific','prominence','prominent','promise','promised','promises','promising','promoter','prompt','promptly','proper','properly','propitious','propitiously','pros','prosper','prosperity','prosperous','prospros','protect','protection','protective','proud','proven','proves','providence','proving','prowess','prudence','prudent','prudently','punctual','pure','purify','purposeful','quaint','qualified','qualify','quicker','quiet','quieter','radiance','radiant','rapid','rapport','rapt','rapture','raptureous','raptureously','rapturous','rapturously','rational','razor-sharp','reachable','readable','readily','ready','reaffirm','reaffirmation','realistic','realizable','reasonable','reasonably','reasoned','reassurance','reassure','receptive','reclaim','recomend','recommend','recommendation','recommendations','recommended','reconcile','reconciliation','record-setting','recover','recovery','rectification','rectify','rectifying','redeem','redeeming','redemption','refine','refined','refinement','reform','reformed','reforming','reforms','refresh','refreshed','refreshing','refund','refunded','regal','regally','regard','rejoice','rejoicing','rejoicingly','rejuvenate','rejuvenated','rejuvenating','relaxed','relent','reliable','reliably','relief','relish','remarkable','remarkably','remedy','remission','remunerate','renaissance','renewed','renown','renowned','replaceable','reputable','reputation','resilient','resolute','resound','resounding','resourceful','resourcefulness','respect','respectable','respectful','respectfully','respite','resplendent','responsibly','responsive','restful','restored','restructure','restructured','restructuring','retractable','revel','revelation','revere','reverence','reverent','reverently','revitalize','revival','revive','revives','revolutionary','revolutionize','revolutionized','revolutionizes','reward','rewarding','rewardingly','rich','richer','richly','richness','right','righten','righteous','righteously','righteousness','rightful','rightfully','rightly','rightness','risk-free','robust','rock-star','rock-stars','rockstar','rockstars','romantic','romantically','romanticize','roomier','roomy','rosy','safe','safely','sagacity','sagely','saint','saintliness','saintly','salutary','salute','sane','satisfactorily','satisfactory','satisfied','satisfies','satisfy','satisfying','satisified','saver','savings','savior','savvy','scenic','seamless','seasoned','secure','securely','selective','self-determination','self-respect','self-satisfaction','self-sufficiency','self-sufficient','sensation','sensational','sensationally','sensations','sensible','sensibly','sensitive','serene','serenity','sexy','sharp','sharper','sharpest','shimmering','shimmeringly','shine','shiny','significant','silent','simpler','simplest','simplified','simplifies','simplify','simplifying','sincere','sincerely','sincerity','skill','skilled','skillful','skillfully','slammin','sleek','slick','smart','smarter','smartest','smartly','smile','smiles','smiling','smilingly','smitten','smooth','smoother','smoothes','smoothest','smoothly','snappy','snazzy','sociable','soft','softer','solace','solicitous','solicitously','solid','solidarity','soothe','soothingly','sophisticated','soulful','soundly','soundness','spacious','sparkle','sparkling','spectacular','spectacularly','speedily','speedy','spellbind','spellbinding','spellbindingly','spellbound','spirited','spiritual','splendid','splendidly','splendor','spontaneous','sporty','spotless','sprightly','stability','stabilize','stable','stainless','standout','state-of-the-art','stately','statuesque','staunch','staunchly','staunchness','steadfast','steadfastly','steadfastness','steadiest','steadiness','steady','stellar','stellarly','stimulate','stimulates','stimulating','stimulative','stirringly','straighten','straightforward','streamlined','striking','strikingly','striving','strong','stronger','strongest','stunned','stunning','stunningly','stupendous','stupendously','sturdier','sturdy','stylish','stylishly','stylized','suave','suavely','sublime','subsidize','subsidized','subsidizes','subsidizing','substantive','succeed','succeeded','succeeding','succeeds','succes','success','successes','successful','successfully','suffice','sufficed','suffices','sufficient','sufficiently',\n",
    "    'suitable','sumptuous','sumptuously','sumptuousness','super','superb','superbly','superior','superiority','supple','support','supported','supporter','supporting','supportive','supports','supremacy','supreme','supremely','supurb','supurbly','surmount','surpass','surreal','survival','survivor','sustainability','sustainable','swank','swankier','swankiest','swanky','sweeping','sweet','sweeten','sweetheart','sweetly','sweetness','swift','swiftness','talent','talented','talents','tantalize','tantalizing','tantalizingly','tempt','tempting','temptingly','tenacious','tenaciously','tenacity','tender','tenderly','terrific','terrifically','thank','thankful','thinner','thoughtful','thoughtfully','thoughtfulness','thrift','thrifty','thrill','thrilled','thrilling','thrillingly','thrills','thrive','thriving','thumb-up','thumbs-up','tickle','tidy','time-honored','timely','tingle','titillate','titillating','titillatingly','togetherness','tolerable','toll-free','top','top-notch','top-quality','topnotch','tops','tough','tougher','toughest','traction','tranquil','tranquility','transparent','treasure','tremendously','trendy','triumph','triumphal','triumphant','triumphantly','trivially','trophy','trouble-free','trump','trumpet','trust','trusted','trusting','trustingly','trustworthiness','trustworthy','trusty','truthful','truthfully','truthfulness','twinkly','ultra-crisp','unabashed','unabashedly','unaffected','unassailable','unbeatable','unbiased','unbound','uncomplicated','unconditional','undamaged','undaunted','understandable','undisputable','undisputably','undisputed','unencumbered','unequivocal','unequivocally','unfazed','unfettered','unforgettable','unity','unlimited','unmatched','unparalleled','unquestionable','unquestionably','unreal','unrestricted','unrivaled','unselfish','unwavering','upbeat','upgradable','upgradeable','upgraded','upheld','uphold','uplift','uplifting','upliftingly','upliftment','upscale','usable','useable','useful','user-friendly','user-replaceable','valiant','valiantly','valor','valuable','variety','venerate','verifiable','veritable','versatile','versatility','vibrant','vibrantly','victorious','victory','viewable','vigilance','vigilant','virtue','virtuous','virtuously','visionary','vivacious','vivid','vouch','vouchsafe','warm','warmer','warmhearted','warmly','warmth','wealthy','welcome','well','well-backlit','well-balanced','well-behaved','well-being','well-bred','well-connected','well-educated','well-established','well-informed','well-intentioned','well-known','well-made','well-managed','well-mannered','well-positioned','well-received','well-regarded','well-rounded','well-run','well-wishers','wellbeing','whoa','wholeheartedly','wholesome','whooa','whoooa','wieldy','willing','willingly','willingness','win','windfall','winnable','winner','winners','winning','wins','wisdom','wise','wisely','witty','won','wonder','wonderful','wonderfully','wonderous','wonderously','wonders','wondrous','woo','work','workable','worked','works','world-famous','worth','worth-while','worthiness','worthwhile','worthy','wow','wowed','wowing','wows','yay','youthful','zeal','zenith','zest','zippy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_words = ['2-faced','2-faces','abnormal','abolish','abominable','abominably','abominate','abomination','abort','aborted','aborts','abrade','abrasive','abrupt','abruptly','abscond','absence','absent-minded','absentee','absurd','absurdity','absurdly','absurdness','abuse','abused','abuses','abusive','abysmal','abysmally','abyss','accidental','accost','accursed','accusation','accusations','accuse','accuses','accusing','accusingly','acerbate','acerbic','acerbically','ache','ached','aches','achey','aching','acrid','acridly','acridness','acrimonious','acrimoniously','acrimony','adamant','adamantly','addict','addicted','addicting','addicts','admonish','admonisher','admonishingly','admonishment','admonition','adulterate','adulterated','adulteration','adulterier','adversarial','adversary','adverse','adversity','afflict','affliction','afflictive','affront','afraid','aggravate','aggravating','aggravation','aggression','aggressive','aggressiveness','aggressor','aggrieve','aggrieved','aggrivation','aghast','agonies','agonize','agonizing','agonizingly','agony','aground','ail','ailing','ailment','aimless','alarm','alarmed','alarming','alarmingly','alienate','alienated','alienation','allegation','allegations','allege','allergic','allergies','allergy','aloof','altercation','ambiguity','ambiguous','ambivalence','ambivalent','ambush','amiss','amputate','anarchism','anarchist','anarchistic','anarchy','anemic','anger','angrily','angriness','angry','anguish','animosity','annihilate','annihilation','annoy','annoyance','annoyances','annoyed','annoying','annoyingly','annoys','anomalous','anomaly','antagonism','antagonist','antagonistic','antagonize','anti-','anti-american','anti-israeli','anti-occupation','anti-proliferation','anti-semites','anti-social','anti-us','anti-white','antipathy','antiquated','antithetical','anxieties','anxiety','anxious','anxiously','anxiousness','apathetic','apathetically','apathy','apocalypse','apocalyptic','apologist','apologists','appal','appall','appalled','appalling','appallingly','apprehension','apprehensions','apprehensive','apprehensively','arbitrary','arcane','archaic','arduous','arduously','argumentative','arrogance','arrogant','arrogantly','ashamed','asinine','asininely','asinininity','askance','asperse','aspersion','aspersions','assail','assassin','assassinate','assault','assult','astray','asunder','atrocious','atrocities','atrocity','atrophy','attack','attacks','audacious','audaciously','audaciousness','audacity','audiciously','austere','authoritarian','autocrat','autocratic','avalanche','avarice','avaricious','avariciously','avenge','averse','aversion','aweful','awful','awfully','awfulness','awkward','awkwardness','ax','babble','back-logged','back-wood','back-woods','backache','backaches','backaching','backbite','backbiting','backward','backwardness','backwood','backwoods','bad','badly','baffle','baffled','bafflement','baffling','bait','balk','banal','banalize','bane','banish','banishment','bankrupt','barbarian','barbaric','barbarically','barbarity','barbarous','barbarously','barren','baseless','bash','bashed','bashful','bashing','bastard','bastards','battered','battering','batty','bearish','beastly','bedlam','bedlamite','befoul','beg','beggar','beggarly','begging','beguile','belabor','belated','beleaguer','belie','belittle','belittled','belittling','bellicose','belligerence','belligerent','belligerently','bemoan','bemoaning','bemused','bent','berate','bereave','bereavement','bereft','berserk','beseech','beset','besiege','besmirch','bestial','betray','betrayal','betrayals','betrayer','betraying','betrays','bewail','beware','bewilder','bewildered','bewildering','bewilderingly','bewilderment','bewitch','bias','biased','biases','bicker','bickering','bid-rigging','bigotries','bigotry','bitch','bitchy','biting','bitingly','bitter','bitterly','bitterness','bizarre','blab','blabber','blackmail','blah','blame','blameworthy','bland','blandish','blaspheme','blasphemous','blasphemy','blasted','blatant','blatantly','blather','bleak','bleakly','bleakness','bleed','bleeding','bleeds','blemish','blind','blinding','blindingly','blindside','blister','blistering','bloated','blockage','blockhead','bloodshed','bloodthirsty','bloody','blotchy','blow','blunder','blundering','blunders','blunt','blur','bluring','blurred','blurring','blurry','blurs','blurt','boastful','boggle','bogus','boil','boiling','boisterous','bomb','bombard','bombardment','bombastic','bondage','bonkers','bore','bored','boredom','bores','boring','botch','bother','bothered','bothering','bothers','bothersome','bowdlerize','boycott','braggart','bragger','brainless','brainwash','brash','brashly','brashness','brat','bravado','brazen','brazenly','brazenness','breach','break','break-up','break-ups','breakdown','breaking','breaks','breakup','breakups','bribery','brimstone','bristle','brittle','broke','broken','broken-hearted','brood','browbeat','bruise','bruised','bruises','bruising','brusque','brutal','brutalising','brutalities','brutality','brutalize','brutalizing','brutally','brute','brutish','bs','buckle','bug','bugging','buggy','bugs','bulkier','bulkiness','bulky','bulkyness','bull****','bull----','bullies','bullshit','bullshyt','bully','bullying','bullyingly','bum','bump','bumped','bumping','bumpping','bumps','bumpy','bungle','bungler','bungling','bunk','burden','burdensome','burdensomely','burn','burned','burning','burns','bust','busts','busybody','butcher','butchery','buzzing','byzantine','cackle','calamities','calamitous','calamitously','calamity','callous','calumniate','calumniation','calumnies','calumnious','calumniously','calumny','cancer','cancerous','cannibal','cannibalize','capitulate','capricious','capriciously','capriciousness','capsize','careless','carelessness','caricature','carnage','carp','cartoonish','cash-strapped','castigate','castrated','casualty','cataclysm','cataclysmal','cataclysmic','cataclysmically','catastrophe','catastrophes','catastrophic','catastrophically','catastrophies','caustic','caustically','cautionary','cave','censure','chafe','chaff','chagrin','challenging','chaos','chaotic','chasten','chastise','chastisement','chatter','chatterbox','cheap','cheapen','cheaply','cheat','cheated','cheater','cheating','cheats','checkered','cheerless','cheesy','chide','childish','chill','chilly','chintzy','choke','choleric','choppy','chore','chronic','chunky','clamor','clamorous','clash','cliche','cliched','clique','clog','clogged','clogs','cloud','clouding','cloudy','clueless','clumsy','clunky','coarse','cocky','coerce','coercion','coercive','cold','coldly','collapse','collude','collusion','combative','combust','comical','commiserate','commonplace','commotion','commotions','complacent','complain','complained','complaining','complains','complaint','complaints','complex','complicated','complication','complicit','compulsion','compulsive','concede','conceded','conceit','conceited','concen','concens','concern','concerned','concerns','concession','concessions','condemn','condemnable','condemnation','condemned','condemns','condescend','condescending','condescendingly','condescension','confess','confession','confessions','confined','conflict','conflicted','conflicting','conflicts','confound','confounded','confounding','confront','confrontation','confrontational','confuse','confused','confuses','confusing','confusion','confusions','congested','congestion','cons','conscons','conservative','conspicuous','conspicuously','conspiracies','conspiracy','conspirator','conspiratorial','conspire','consternation','contagious','contaminate','contaminated','contaminates','contaminating','contamination','contempt','contemptible','contemptuous','contemptuously','contend','contention','contentious','contort','contortions','contradict','contradiction','contradictory','contrariness','contravene','contrive','contrived','controversial','controversy','convoluted','corrode','corrosion','corrosions','corrosive','corrupt','corrupted','corrupting','corruption','corrupts','corruptted','costlier','costly','counter-productive','counterproductive','coupists','covetous','coward','cowardly','crabby','crack','cracked','cracks','craftily','craftly','crafty','cramp','cramped','cramping','cranky','crap','crappy','craps','crash','crashed','crashes','crashing','crass','craven','cravenly','craze','crazily','craziness','crazy','creak','creaking','creaks','credulous','creep','creeping','creeps','creepy','crept','crime','criminal','cringe','cringed','cringes','cripple','crippled','cripples','crippling','crisis','critic','critical','criticism','criticisms','criticize','criticized','criticizing','critics','cronyism','crook','crooked','crooks','crowded','crowdedness','crude','cruel','crueler','cruelest','cruelly','cruelness','cruelties','cruelty','crumble','crumbling','crummy','crumple','crumpled','crumples','crush','crushed','crushing','cry','culpable','culprit','cumbersome','cunt','cunts','cuplrit','curse','cursed','curses','curt','cuss','cussed','cutthroat','cynical','cynicism','d*mn','damage','damaged','damages','damaging','damn','damnable','damnably','damnation','damned','damning','damper','danger','dangerous','dangerousness','dark','darken','darkened','darker','darkness','dastard','dastardly','daunt','daunting','dauntingly','dawdle','daze','dazed','dead','deadbeat','deadlock','deadly','deadweight','deaf','dearth','death','debacle','debase','debasement','debaser','debatable','debauch','debaucher','debauchery','debilitate','debilitating','debility','debt','debts','decadence','decadent','decay','decayed','deceit','deceitful','deceitfully','deceitfulness','deceive','deceiver','deceivers','deceiving','deception','deceptive','deceptively','declaim','decline','declines','declining','decrement','decrepit','decrepitude','decry','defamation','defamations','defamatory','defame','defect','defective','defects','defensive','defiance','defiant','defiantly','deficiencies','deficiency','deficient','defile','defiler','deform','deformed','defrauding','defunct','defy','degenerate','degenerately','degeneration','degradation','degrade','degrading','degradingly','dehumanization','dehumanize','deign','deject','dejected','dejectedly','dejection','delay','delayed','delaying','delays','delinquency','delinquent','delirious','delirium','delude','deluded','deluge','delusion','delusional','delusions','demean','demeaning','demise','demolish','demolisher','demon','demonic','demonize','demonized','demonizes','demonizing','demoralize','demoralizing','demoralizingly','denial','denied','denies','denigrate','denounce','dense','dent','dented','dents','denunciate','denunciation','denunciations','deny','denying','deplete','deplorable','deplorably','deplore','deploring','deploringly','deprave','depraved','depravedly','deprecate','depress','depressed','depressing','depressingly','depression','depressions','deprive','deprived','deride','derision','derisive','derisively','derisiveness','derogatory','desecrate','desert','desertion','desiccate','desiccated','desititute','desolate','desolately','desolation','despair','despairing','despairingly','desperate','desperately','desperation','despicable','despicably','despise','despised','despoil','despoiler','despondence','despondency','despondent','despondently','despot','despotic','despotism','destabilisation','destains','destitute','destitution','destroy','destroyer','destruction','destructive','desultory','deter','deteriorate','deteriorating','deterioration','deterrent','detest','detestable','detestably','detested','detesting','detests','detract','detracted','detracting','detraction','detracts','detriment','detrimental','devastate','devastated','devastates','devastating','devastatingly','devastation','deviate','deviation','devil','devilish','devilishly','devilment','devilry','devious','deviously','deviousness','devoid','diabolic','diabolical','diabolically','diametrically','diappointed','diatribe','diatribes','dick','dictator','dictatorial','die','die-hard','died','dies','difficult','difficulties','difficulty','diffidence','dilapidated','dilemma','dilly-dally','dim','dimmer','din','ding','dings','dinky','dire','direly','direness','dirt','dirtbag','dirtbags','dirts','dirty','disable','disabled','disaccord','disadvantage','disadvantaged','disadvantageous','disadvantages','disaffect','disaffected','disaffirm','disagree','disagreeable','disagreeably','disagreed','disagreeing','disagreement','disagrees','disallow','disapointed','disapointing','disapointment','disappoint','disappointed','disappointing','disappointingly','disappointment','disappointments','disappoints','disapprobation','disapproval','disapprove','disapproving','disarm','disarray','disaster','disasterous','disastrous','disastrously','disavow','disavowal','disbelief','disbelieve','disbeliever','disclaim','discombobulate','discomfit','discomfititure','discomfort','discompose','disconcert','disconcerted','disconcerting','disconcertingly','disconsolate','disconsolately','disconsolation','discontent','discontented','discontentedly','discontinued','discontinuity','discontinuous','discord','discordance','discordant','discountenance','discourage','discouragement','discouraging','discouragingly','discourteous','discourteously','discoutinous','discredit','discrepant','discriminate','discrimination','discriminatory','disdain','disdained','disdainful','disdainfully','disfavor','disgrace','disgraced','disgraceful','disgracefully','disgruntle','disgruntled','disgust','disgusted','disgustedly','disgustful','disgustfully','disgusting','disgustingly','dishearten','disheartening','dishearteningly','dishonest','dishonestly','dishonesty','dishonor','dishonorable','dishonorablely','disillusion','disillusioned','disillusionment','disillusions','disinclination','disinclined','disingenuous','disingenuously','disintegrate','disintegrated','disintegrates','disintegration','disinterest','disinterested','dislike','disliked','dislikes','disliking','dislocated','disloyal','disloyalty','dismal','dismally','dismalness','dismay','dismayed','dismaying','dismayingly','dismissive','dismissively','disobedience','disobedient','disobey','disoobedient','disorder','disordered','disorderly','disorganized','disorient','disoriented','disown','disparage','disparaging','disparagingly','dispensable','dispirit','dispirited','dispiritedly','dispiriting','displace','displaced','displease','displeased','displeasing','displeasure','disproportionate','disprove','disputable','dispute','disputed','disquiet','disquieting','disquietingly','disquietude','disregard','disregardful','disreputable','disrepute','disrespect','disrespectable','disrespectablity','disrespectful','disrespectfully','disrespectfulness','disrespecting','disrupt','disruption','disruptive','diss','dissapointed','dissappointed','dissappointing','dissatisfaction','dissatisfactory','dissatisfied','dissatisfies','dissatisfy','dissatisfying','dissed','dissemble','dissembler','dissension','dissent','dissenter','dissention','disservice','disses','dissidence','dissident','dissidents','dissing','dissocial','dissolute','dissolution','dissonance','dissonant','dissonantly','dissuade','dissuasive','distains','distaste','distasteful','distastefully','distort','distorted','distortion','distorts','distract','distracting','distraction','distraught','distraughtly','distraughtness','distress','distressed','distressing','distressingly','distrust','distrustful','distrusting','disturb','disturbance','disturbed','disturbing','disturbingly','disunity','disvalue','divergent','divisive','divisively','divisiveness','dizzing','dizzingly','dizzy','doddering','dodgey','dogged','doggedly','dogmatic','doldrums','domineer','domineering','donside','doom','doomed','doomsday','dope','doubt','doubtful','doubtfully','doubts','douchbag','douchebag','douchebags','downbeat','downcast','downer','downfall','downfallen','downgrade','downhearted','downheartedly','downhill','downside','downsides','downturn','downturns','drab','draconian','draconic','drag','dragged','dragging','dragoon','drags','drain','drained','draining','drains','drastic','drastically','drawback','drawbacks','dread','dreadful','dreadfully','dreadfulness','dreary','dripped','dripping','drippy','drips','drones','droop','droops','drop-out','drop-outs','dropout','dropouts','drought','drowning','drunk','drunkard','drunken','dubious','dubiously','dubitable','dud','dull','dullard','dumb','dumbfound','dump','dumped','dumping','dumps','dunce','dungeon','dungeons','dupe','dust','dusty','dwindling','dying','earsplitting','eccentric','eccentricity','effigy','effrontery','egocentric','egomania','egotism','egotistical','egotistically','egregious','egregiously','election-rigger','elimination','emaciated','emasculate','embarrass','embarrassing','embarrassingly','embarrassment','embattled','embroil','embroiled','embroilment','emergency','emphatic','emphatically','emptiness','encroach','encroachment','endanger','enemies','enemy','enervate','enfeeble','enflame','engulf','enjoin','enmity','enrage','enraged','enraging','enslave','entangle','entanglement','entrap','entrapment','envious','enviously','enviousness','epidemic','equivocal','erase','erode','erodes','erosion','err','errant','erratic','erratically','erroneous','erroneously','error','errors','eruptions','escapade','eschew','estranged','evade','evasion','evasive','evil','evildoer','evils','eviscerate','exacerbate','exagerate','exagerated','exagerates','exaggerate','exaggeration','exasperate','exasperated','exasperating','exasperatingly','exasperation','excessive','excessively','exclusion','excoriate','excruciating','excruciatingly','excuse','excuses','execrate','exhaust','exhausted','exhaustion','exhausts','exhorbitant','exhort','exile','exorbitant','exorbitantance','exorbitantly','expel','expensive','expire','expired','explode','exploit','exploitation','explosive','expropriate','expropriation','expulse','expunge','exterminate','extermination','extinguish','extort','extortion','extraneous','extravagance','extravagant','extravagantly','extremism','extremist','extremists','eyesore','f**k','fabricate','fabrication','facetious','facetiously','fail','failed','failing','fails','failure','failures','faint','fainthearted','faithless','fake','fall','fallacies','fallacious','fallaciously','fallaciousness','fallacy','fallen','falling','fallout','falls','false','falsehood','falsely','falsify','falter','faltered','famine','famished','fanatic','fanatical','fanatically','fanaticism','fanatics','fanciful','far-fetched','farce','farcical','farcical-yet-provocative','farcically','farfetched','fascism','fascist','fastidious','fastidiously','fastuous','fat','fat-cat','fat-cats','fatal','fatalistic','fatalistically','fatally','fatcat','fatcats','fateful','fatefully','fathomless','fatigue','fatigued','fatique','fatty','fatuity','fatuous','fatuously','fault','faults','faulty','fawningly','faze','fear','fearful','fearfully','fears','fearsome','feckless','feeble','feeblely','feebleminded','feign','feint','fell','felon','felonious','ferociously','ferocity','fetid','fever','feverish','fevers','fiasco','fib','fibber','fickle','fiction','fictional','fictitious','fidget','fidgety','fiend','fiendish','fierce','figurehead','filth','filthy','finagle','finicky','fissures','fist','flabbergast','flabbergasted','flagging','flagrant','flagrantly','flair','flairs','flak','flake','flakey','flakieness','flaking','flaky','flare','flares','flareup','flareups','flat-out','flaunt','flaw','flawed','flaws','flee','fleed','fleeing','fleer','flees','fleeting','flicering','flicker','flickering','flickers','flighty','flimflam','flimsy','flirt','flirty','floored','flounder','floundering','flout','fluster','foe','fool','fooled','foolhardy','foolish','foolishly','foolishness','forbid','forbidden','forbidding','forceful','foreboding','forebodingly','forfeit','forged','forgetful','forgetfully','forgetfulness','forlorn','forlornly','forsake','forsaken','forswear','foul','foully','foulness','fractious','fractiously','fracture','fragile','fragmented','frail','frantic','frantically','franticly','fraud','fraudulent','fraught','frazzle','frazzled','freak','freaking','freakish','freakishly','freaks','freeze','freezes','freezing','frenetic','frenetically','frenzied','frenzy','fret','fretful','frets','friction','frictions','fried','friggin','frigging','fright','frighten','frightening','frighteningly','frightful','frightfully','frigid','frost','frown','froze','frozen','fruitless','fruitlessly','frustrate','frustrated','frustrates','frustrating','frustratingly','frustration','frustrations','fuck','fucking','fudge','fugitive','full-blown','fulminate','fumble','fume','fumes','fundamentalism','funky','funnily','funny','furious','furiously','furor','fury','fuss','fussy','fustigate','fusty','futile','futilely','futility','fuzzy','gabble','gaff','gaffe','gainsay','gainsayer','gall','galling','gallingly','galls','gangster','gape','garbage','garish','gasp','gauche','gaudy','gawk','gawky','geezer','genocide','get-rich','ghastly','ghetto','ghosting','gibber','gibberish','gibe','giddy','gimmick','gimmicked','gimmicking','gimmicks','gimmicky','glare','glaringly','glib','glibly','glitch','glitches','gloatingly','gloom','gloomy','glower','glum','glut','gnawing','goad','goading','god-awful','goof','goofy','goon','gossip','graceless','gracelessly','graft','grainy','grapple','grate','grating','gravely','greasy','greed','greedy','grief','grievance','grievances','grieve','grieving','grievous','grievously','grim','grimace','grind','gripe','gripes','grisly','gritty','gross','grossly','grotesque','grouch','grouchy','groundless','grouse','growl','grudge','grudges','grudging','grudgingly','gruesome','gruesomely','gruff','grumble','grumpier','grumpiest','grumpily','grumpish','grumpy','guile','guilt','guiltily','guilty','gullible','gutless','gutter','hack','hacks','haggard','haggle','hairloss','halfhearted','halfheartedly','hallucinate','hallucination','hamper','hampered','handicapped','hang','hangs','haphazard','hapless','harangue','harass','harassed','harasses','harassment','harboring','harbors','hard','hard-hit','hard-line','hard-liner','hardball','harden','hardened','hardheaded','hardhearted','hardliner','hardliners','hardship','hardships','harm','harmed','harmful','harms','harpy','harridan','harried','harrow','harsh','harshly','hasseling','hassle','hassled','hassles','haste','hastily','hasty','hate','hated','hateful','hatefully','hatefulness','hater','haters','hates','hating','hatred','haughtily','haughty','haunt','haunting','havoc','hawkish','haywire','hazard','hazardous','haze','hazy','head-aches','headache','headaches','heartbreaker','heartbreaking','heartbreakingly','heartless','heathen','heavy-handed','heavyhearted','heck','heckle','heckled','heckles','hectic','hedge','hedonistic','heedless','hefty','hegemonism','hegemonistic','hegemony','heinous','hell','hell-bent','hellion','hells','helpless','helplessly','helplessness','heresy','heretic','heretical','hesitant','hestitant','hideous','hideously','hideousness','high-priced','hiliarious','hinder','hindrance','hiss','hissed','hissing','ho-hum','hoard','hoax','hobble','hogs','hollow','hoodium','hoodwink','hooligan','hopeless','hopelessly','hopelessness','horde','horrendous','horrendously','horrible','horrid','horrific','horrified','horrifies','horrify','horrifying','horrifys','hostage','hostile','hostilities','hostility','hotbeds','hothead','hotheaded','hothouse','hubris','huckster','hum','humid','humiliate','humiliating','humiliation','humming','hung','hurt','hurted','hurtful','hurting','hurts','hustler','hype','hypocricy','hypocrisy','hypocrite','hypocrites','hypocritical','hypocritically','hysteria','hysteric','hysterical','hysterically','hysterics','idiocies','idiocy','idiot','idiotic','idiotically','idiots','idle','ignoble','ignominious','ignominiously','ignominy','ignorance','ignorant','ignore','ill-advised','ill-conceived','ill-defined','ill-designed','ill-fated','ill-favored','ill-formed','ill-mannered','ill-natured','ill-sorted','ill-tempered','ill-treated','ill-treatment','ill-usage','ill-used','illegal','illegally','illegitimate','illicit','illiterate','illness','illogic','illogical','illogically','illusion','illusions','illusory','imaginary','imbalance','imbecile','imbroglio','immaterial','immature','imminence','imminently','immobilized','immoderate','immoderately','immodest','immoral','immorality','immorally','immovable','impair','impaired','impasse','impatience','impatient','impatiently','impeach','impedance','impede','impediment','impending','impenitent','imperfect','imperfection','imperfections','imperfectly','imperialist','imperil','imperious','imperiously','impermissible','impersonal','impertinent','impetuous','impetuously','impiety','impinge','impious','implacable','implausible','implausibly','implicate','implication','implode','impolite','impolitely','impolitic','importunate','importune','impose','imposers','imposing','imposition','impossible','impossiblity','impossibly','impotent','impoverish','impoverished','impractical','imprecate','imprecise','imprecisely','imprecision','imprison','imprisonment','improbability','improbable','improbably','improper','improperly','impropriety','imprudence','imprudent','impudence','impudent','impudently','impugn','impulsive','impulsively','impunity','impure','impurity','inability','inaccuracies','inaccuracy','inaccurate','inaccurately','inaction','inactive','inadequacy','inadequate','inadequately','inadverent','inadverently','inadvisable','inadvisably','inane','inanely','inappropriate','inappropriately','inapt','inaptitude','inarticulate','inattentive','inaudible','incapable','incapably','incautious','incendiary','incense','incessant','incessantly','incite','incitement','incivility','inclement','incognizant','incoherence','incoherent','incoherently','incommensurate','incomparable','incomparably','incompatability','incompatibility','incompatible','incompetence','incompetent','incompetently','incomplete','incompliant','incomprehensible','incomprehension','inconceivable','inconceivably','incongruous','incongruously','inconsequent','inconsequential','inconsequentially','inconsequently','inconsiderate','inconsiderately','inconsistence','inconsistencies','inconsistency','inconsistent','inconsolable','inconsolably','inconstant','inconvenience','inconveniently','incorrect','incorrectly','incorrigible','incorrigibly','incredulous','incredulously','inculcate','indecency','indecent','indecently','indecision','indecisive','indecisively','indecorum','indefensible','indelicate','indeterminable','indeterminably','indeterminate','indifference','indifferent','indigent','indignant','indignantly','indignation','indignity','indiscernible','indiscreet','indiscreetly','indiscretion','indiscriminate','indiscriminately','indiscriminating','indistinguishable','indoctrinate','indoctrination','indolent','indulge','ineffective','ineffectively','ineffectiveness','ineffectual','ineffectually','ineffectualness','inefficacious','inefficacy','inefficiency','inefficient','inefficiently','inelegance','inelegant','ineligible','ineloquent','ineloquently','inept','ineptitude','ineptly','inequalities','inequality','inequitable','inequitably','inequities','inescapable','inescapably','inessential','inevitable','inevitably','inexcusable','inexcusably','inexorable','inexorably','inexperience','inexperienced','inexpert','inexpertly','inexpiable','inexplainable','inextricable','inextricably','infamous','infamously','infamy','infected','infection','infections','inferior','inferiority','infernal','infest','infested','infidel','infidels','infiltrator','infiltrators','infirm','inflame','inflammation','inflammatory','inflammed','inflated','inflationary','inflexible','inflict','infraction','infringe','infringement','infringements','infuriate','infuriated','infuriating','infuriatingly','inglorious','ingrate','ingratitude','inhibit','inhibition','inhospitable','inhospitality','inhuman','inhumane','inhumanity','inimical','inimically','iniquitous','iniquity','injudicious','injure','injurious','injury','injustice','injustices','innuendo','inoperable','inopportune','inordinate','inordinately','insane','insanely','insanity','insatiable','insecure','insecurity','insensible','insensitive','insensitively','insensitivity','insidious','insidiously','insignificance','insignificant','insignificantly','insincere','insincerely','insincerity','insinuate','insinuating','insinuation','insociable','insolence','insolent','insolently','insolvent','insouciance','instability','instable','instigate','instigator','instigators','insubordinate','insubstantial','insubstantially','insufferable','insufferably','insufficiency','insufficient','insufficiently','insular','insult','insulted','insulting','insultingly','insults','insupportable','insupportably','insurmountable','insurmountably','insurrection','intefere','inteferes','intense','interfere','interference','interferes','intermittent','interrupt','interruption','interruptions','intimidate','intimidating','intimidatingly','intimidation','intolerable','intolerablely','intolerance','intoxicate','intractable','intransigence','intransigent','intrude','intrusion','intrusive','inundate','inundated','invader','invalid','invalidate','invalidity','invasive','invective','inveigle','invidious','invidiously','invidiousness','invisible','involuntarily','involuntary','irascible','irate','irately','ire','irk','irked','irking','irks','irksome','irksomely','irksomeness','irksomenesses','ironic','ironical','ironically','ironies','irony','irragularity','irrational','irrationalities','irrationality','irrationally','irrationals','irreconcilable','irrecoverable','irrecoverableness','irrecoverablenesses','irrecoverably','irredeemable','irredeemably','irreformable','irregular','irregularity','irrelevance','irrelevant','irreparable','irreplacible','irrepressible','irresolute','irresolvable','irresponsible','irresponsibly','irretating','irretrievable','irreversible','irritable','irritably','irritant','irritate','irritated','irritating','irritation','irritations','isolate','isolated','isolation','issue','issues','itch','itching','itchy','jabber','jaded','jagged','jam','jarring','jaundiced','jealous','jealously','jealousness','jealousy','jeer','jeering','jeeringly','jeers','jeopardize','jeopardy','jerk','jerky','jitter','jitters','jittery','job-killing','jobless','joke','joker','jolt','judder','juddering','judders','jumpy','junk','junky','junkyard','jutter','jutters','kaput','kill','killed','killer','killing','killjoy','kills','knave','knife','knock','knotted','kook','kooky','lack','lackadaisical','lacked','lackey','lackeys','lacking','lackluster','lacks','laconic','lag','lagged','lagging','laggy','lags','laid-off','lambast','lambaste','lame','lame-duck','lament','lamentable','lamentably','languid','languish','languor','languorous','languorously','lanky','lapse','lapsed','lapses','lascivious','last-ditch','latency','laughable','laughably','laughingstock','lawbreaker','lawbreaking','lawless','lawlessness','layoff','layoff-happy','lazy','leak','leakage','leakages','leaking','leaks','leaky','lech','lecher','lecherous','lechery','leech','leer','leery','left-leaning','lemon','lengthy','less-developed','lesser-known','letch','lethal','lethargic','lethargy','lewd','lewdly','lewdness','liability','liable','liar','liars','licentious','licentiously','licentiousness','lie','lied','lier','lies','life-threatening','lifeless','limit','limitation','limitations','limited','limits','limp','listless','litigious','little-known','livid','lividly','loath','loathe','loathing','loathly','loathsome','loathsomely','lone','loneliness','lonely','loner','lonesome','long-time','long-winded','longing','longingly','loophole','loopholes','loose','loot','lorn','lose','loser','losers','loses','losing','loss','losses','lost','loud','louder','lousy','loveless','lovelorn','low-rated','lowly','ludicrous','ludicrously','lugubrious','lukewarm','lull','lumpy','lunatic','lunaticism','lurch','lure','lurid','lurk','lurking','lying','macabre','mad','madden','maddening','maddeningly','madder','madly','madman','madness','maladjusted','maladjustment','malady','malaise','malcontent','malcontented','maledict','malevolence','malevolent','malevolently','malice','malicious','maliciously','maliciousness','malign','malignant','malodorous','maltreatment','mangle','mangled','mangles','mangling','mania','maniac','maniacal','manic','manipulate','manipulation','manipulative','manipulators','mar','marginal','marginally','martyrdom','martyrdom-seeking','mashed','massacre','massacres','matte','mawkish','mawkishly','mawkishness','meager','meaningless','meanness','measly','meddle','meddlesome','mediocre','mediocrity','melancholy','melodramatic','melodramatically','meltdown','menace','menacing','menacingly','mendacious','mendacity','menial','merciless','mercilessly','mess','messed','messes','messing','messy','midget','miff','militancy','mindless','mindlessly','mirage','mire','misalign','misaligned','misaligns','misapprehend','misbecome','misbecoming','misbegotten','misbehave','misbehavior','miscalculate','miscalculation','miscellaneous','mischief','mischievous','mischievously','misconception','misconceptions','miscreant','miscreants','misdirection','miser','miserable','miserableness','miserably','miseries','miserly','misery','misfit','misfortune','misgiving','misgivings','misguidance','misguide','misguided','mishandle','mishap','misinform','misinformed','misinterpret','misjudge','misjudgment','mislead','misleading','misleadingly','mislike','mismanage','mispronounce','mispronounced','mispronounces','misread','misreading','misrepresent','misrepresentation','miss','missed','misses','misstatement','mist','mistake','mistaken','mistakenly','mistakes','mistified','mistress','mistrust','mistrustful','mistrustfully','mists','misunderstand','misunderstanding','misunderstandings','misunderstood','misuse','moan','mobster','mock','mocked','mockeries','mockery','mocking','mockingly','mocks','molest','molestation','monotonous','monotony','monster','monstrosities','monstrosity','monstrous','monstrously','moody','moot','mope','morbid','morbidly','mordant','mordantly','moribund','moron','moronic','morons','mortification','mortified','mortify','mortifying','motionless','motley','mourn','mourner','mournful','mournfully','muddle','muddy','mudslinger','mudslinging','mulish','multi-polarization','mundane','murder','murderer','murderous','murderously','murky','muscle-flexing','mushy','musty','mysterious','mysteriously','mystery','mystify','myth','nag','nagging','naive','naively','narrower','nastily','nastiness','nasty','naughty','nauseate','nauseates','nauseating','nauseatingly','naÔve','nebulous','nebulously','needless','needlessly','needy','nefarious','nefariously','negate','negation','negative','negatives','negativity','neglect','neglected','negligence','negligent','nemesis','nepotism','nervous','nervously','nervousness','nettle','nettlesome','neurotic','neurotically','niggle','niggles','nightmare','nightmarish','nightmarishly','nitpick','nitpicking','noise','noises','noisier','noisy','non-confidence','nonexistent','nonresponsive','nonsense','nosey','notoriety','notorious','notoriously','noxious','nuisance','numb','obese','object','objection','objectionable','objections','oblique','obliterate','obliterated','oblivious','obnoxious','obnoxiously','obscene','obscenely','obscenity','obscure','obscured','obscures','obscurity','obsess','obsessive','obsessively','obsessiveness','obsolete','obstacle','obstinate','obstinately','obstruct','obstructed','obstructing','obstruction','obstructs','obtrusive','obtuse','occlude','occluded','occludes','occluding','odd','odder','oddest','oddities','oddity','oddly','odor','offence','offend','offender','offending','offenses','offensive','offensively','offensiveness','officious','ominous','ominously','omission','omit','one-sided','onerous','onerously','onslaught','opinionated','opponent','opportunistic','oppose','opposition','oppositions','oppress','oppression','oppressive','oppressively','oppressiveness','oppressors','ordeal','orphan','ostracize','outbreak','outburst','outbursts','outcast','outcry','outlaw','outmoded','outrage','outraged','outrageous','outrageously','outrageousness','outrages','outsider','over-acted','over-awe','over-balanced','over-hyped','over-priced','over-valuation','overact','overacted','overawe','overbalance','overbalanced','overbearing','overbearingly','overblown','overdo','overdone','overdue','overemphasize','overheat','overkill','overloaded','overlook','overpaid','overpayed','overplay','overpower','overpriced','overrated','overreach','overrun','overshadow','oversight','oversights','oversimplification','oversimplified','oversimplify','oversize','overstate','overstated','overstatement','overstatements','overstates','overtaxed','overthrow','overthrows','overturn','overweight','overwhelm','overwhelmed','overwhelming','overwhelmingly','overwhelms','overzealous','overzealously','overzelous','pain','painful','painfull','painfully','pains','pale','pales','paltry','pan','pandemonium','pander','pandering','panders','panic','panick','panicked','panicking','panicky','paradoxical','paradoxically','paralize','paralyzed','paranoia','paranoid','parasite','pariah','parody','partiality','partisan','partisans','passe','passive','passiveness','pathetic','pathetically','patronize','paucity','pauper','paupers','payback','peculiar','peculiarly','pedantic','peeled','peeve','peeved','peevish','peevishly','penalize','penalty','perfidious','perfidity','perfunctory','peril','perilous','perilously','perish','pernicious','perplex','perplexed','perplexing','perplexity','persecute','persecution','pertinacious','pertinaciously','pertinacity','perturb','perturbed','pervasive','perverse','perversely','perversion','perversity','pervert','perverted','perverts','pessimism','pessimistic','pessimistically','pest','pestilent','petrified','petrify','pettifog','petty','phobia','phobic','phony','picket','picketed','picketing','pickets','picky','pig','pigs','pillage','pillory','pimple','pinch','pique','pitiable','pitiful','pitifully','pitiless','pitilessly','pittance','pity','plagiarize','plague','plasticky','plaything','plea','pleas','plebeian','plight','plot','plotters','ploy','plunder','plunderer','pointless','pointlessly','poison','poisonous','poisonously','pokey','poky','polarisation','polemize','pollute','polluter','polluters','polution','pompous','poor','poorer','poorest','poorly','posturing','pout','poverty','powerless','prate','pratfall','prattle','precarious','precariously','precipitate','precipitous','predatory','predicament','prejudge','prejudice','prejudices','prejudicial','premeditated','preoccupy','preposterous','preposterously','presumptuous','presumptuously','pretence','pretend','pretense','pretentious','pretentiously','prevaricate','pricey','pricier','prick','prickle','prickles','prideful','prik','primitive','prison','prisoner','problem','problematic','problems','procrastinate','procrastinates','procrastination','profane','profanity','prohibit','prohibitive','prohibitively','propaganda','propagandize','proprietary','prosecute','protest','protested','protesting','protests','protracted','provocation','provocative','provoke','pry','pugnacious','pugnaciously','pugnacity','punch','punish','punishable','punitive','punk','puny','puppet','puppets','puzzled','puzzlement','puzzling','quack','qualm','qualms','quandary','quarrel','quarrellous','quarrellously','quarrels','quarrelsome','quash','queer','questionable','quibble','quibbles','quitter','rabid','racism','racist','racists','racy','radical','radicalization','radically','radicals','rage','ragged','raging','rail','raked','rampage','rampant','ramshackle','rancor','randomly','rankle','rant','ranted','ranting','rantingly','rants','rape','raped','raping','rascal','rascals','rash','rattle','rattled','rattles','ravage','raving','reactionary','rebellious','rebuff','rebuke','recalcitrant','recant','recession','recessionary','reckless','recklessly','recklessness','recoil','recourses','redundancy','redundant','refusal','refuse','refused','refuses','refusing','refutation','refute','refuted','refutes','refuting','regress','regression','regressive','regret','regreted','regretful','regretfully','regrets','regrettable','regrettably','regretted','reject','rejected','rejecting','rejection','rejects','relapse','relentless','relentlessly','relentlessness','reluctance','reluctant','reluctantly','remorse','remorseful','remorsefully','remorseless','remorselessly','remorselessness','renounce','renunciation','repel','repetitive','reprehensible','reprehensibly','reprehension','reprehensive','repress','repression','repressive','reprimand','reproach','reproachful','reprove','reprovingly','repudiate','repudiation','repugn','repugnance','repugnant','repugnantly','repulse','repulsed','repulsing','repulsive','repulsively','repulsiveness','resent','resentful','resentment','resignation','resigned','resistance','restless','restlessness','restrict','restricted','restriction','restrictive','resurgent','retaliate','retaliatory','retard','retarded','retardedness','retards','reticent','retract','retreat','retreated','revenge','revengeful','revengefully','revert','revile','reviled','revoke','revolt','revolting','revoltingly','revulsion','revulsive','rhapsodize','rhetoric','rhetorical','ricer','ridicule','ridicules','ridiculous','ridiculously','rife','rift','rifts','rigid','rigidity','rigidness','rile','riled','rip','rip-off','ripoff','ripped','risk','risks','risky','rival','rivalry','roadblocks','rocky','rogue','rollercoaster','rot','rotten','rough','rremediable','rubbish','rude','rue','ruffian','ruffle','ruin','ruined','ruining','ruinous','ruins','rumbling','rumor','rumors','rumours','rumple','run-down','runaway','rupture','rust','rusts','rusty','rut','ruthless','ruthlessly','ruthlessness','ruts','sabotage','sack','sacrificed','sad','sadden','sadly','sadness','sag','sagged','sagging','saggy','sags','salacious','sanctimonious','sap','sarcasm','sarcastic','sarcastically','sardonic','sardonically','sass','satirical','satirize','savage','savaged','savagery','savages','scaly','scam','scams','scandal','scandalize','scandalized','scandalous','scandalously','scandals','scandel','scandels','scant','scapegoat','scar','scarce','scarcely','scarcity','scare','scared','scarier','scariest','scarily','scarred','scars','scary','scathing','scathingly','sceptical','scoff','scoffingly','scold','scolded','scolding','scoldingly','scorching','scorchingly','scorn','scornful','scornfully','scoundrel','scourge','scowl','scramble','scrambled','scrambles','scrambling','scrap','scratch','scratched','scratches','scratchy','scream','screech','screw-up','screwed','screwed-up','screwy','scuff','scuffs','scum','scummy','second-class','second-tier','secretive','sedentary','seedy','seethe','seething','self-coup','self-criticism','self-defeating','self-destructive','self-humiliation','self-interest','self-interested','self-serving','selfinterested','selfish','selfishly','selfishness','semi-retarded','senile','sensationalize','senseless','senselessly','seriousness','sermonize','servitude','set-up','setback','setbacks','sever','severe','severity','sh*t','shabby','shadowy','shady','shake','shaky','shallow','sham','shambles','shame','shameful','shamefully','shamefulness','shameless','shamelessly','shamelessness','shark','sharply','shatter','shemale','shimmer','shimmy','shipwreck','shirk','shirker','shit','shiver','shock','shocked','shocking','shockingly','shoddy','short-lived','shortage','shortchange','shortcoming','shortcomings','shortness','shortsighted','shortsightedness','showdown','shrew','shriek','shrill','shrilly','shrivel','shroud','shrouded','shrug','shun','shunned','sick','sicken','sickening','sickeningly','sickly','sickness','sidetrack','sidetracked','siege','sillily','silly','simplistic','simplistically','sin','sinful','sinfully','sinister','sinisterly','sink','sinking','skeletons','skeptic','skeptical','skeptically','skepticism','sketchy','skimpy','skinny','skittish','skittishly','skulk','slack','slander','slanderer','slanderous','slanderously','slanders','slap','slashing','slaughter','slaughtered','slave','slaves','sleazy','slime','slog','slogged','slogging','slogs','sloooooooooooooow','sloooow','slooow','sloow','sloppily','sloppy','sloth','slothful','slow','slow-moving','slowed','slower','slowest','slowly','sloww','slowww','slowwww','slug','sluggish','slump','slumping','slumpping','slur','slut','sluts','sly','smack','smallish','smash','smear','smell','smelled','smelling','smells','smelly','smelt','smoke','smokescreen','smolder','smoldering','smother','smoulder','smouldering','smudge','smudged','smudges','smudging','smug','smugly','smut','smuttier','smuttiest','smutty','snag','snagged','snagging','snags','snappish','snappishly','snare','snarky','snarl','sneak','sneakily','sneaky','sneer','sneering','sneeringly','snob','snobbish','snobby','snobish','snobs','snub','so-cal','soapy','sob','sober','sobering','solemn','solicitude','somber','sore','sorely','soreness','sorrow','sorrowful','sorrowfully','sorry','sour','sourly','spade','spank','spendy','spew','spewed','spewing','spews','spilling','spinster','spiritless','spite','spiteful','spitefully','spitefulness','splatter','split','splitting','spoil','spoilage','spoilages','spoiled','spoilled','spoils','spook','spookier','spookiest','spookily','spooky','spoon-fed','spoon-feed','spoonfed','sporadic','spotty','spurious','spurn','sputter','squabble','squabbling','squander','squash','squeak','squeaks','squeaky','squeal','squealing','squeals','squirm','stab','stagnant','stagnate','stagnation','staid','stain','stains','stale','stalemate','stall','stalls','stammer','stampede','standstill','stark','starkly','startle','startling','startlingly','starvation','starve','static','steal','stealing','steals','steep','steeply','stench','stereotype','stereotypical','stereotypically','stern','stew','sticky','stiff','stiffness','stifle','stifling','stiflingly','stigma','stigmatize','sting','stinging','stingingly','stingy','stink','stinks','stodgy','stole','stolen','stooge','stooges','stormy','straggle','straggler','strain','strained','straining','strange','strangely','stranger','strangest','strangle','streaky','strenuous','stress','stresses','stressful','stressfully','stricken','strict','strictly','strident','stridently','strife','strike','stringent','stringently','struck','struggle','struggled','struggles','struggling','strut','stubborn','stubbornly','stubbornness','stuck','stuffy','stumble','stumbled','stumbles','stump','stumped','stumps','stun','stunt','stunted','stupid','stupidest','stupidity','stupidly','stupified','stupify','stupor','stutter','stuttered','stuttering','stutters','sty','stymied','sub-par','subdued','subjected','subjection','subjugate','subjugation','submissive','subordinate','subpoena','subpoenas','subservience','subservient','substandard','subtract','subversion','subversive','subversively','subvert','succumb','suck','sucked','sucker','sucks','sucky','sue','sued','sueing','sues','suffer','suffered','sufferer','sufferers','suffering','suffers','suffocate','sugar-coat','sugar-coated','sugarcoated','suicidal','suicide','sulk','sullen','sully','sunder','sunk','sunken','superficial','superficiality','superficially','superfluous','superstition','superstitious','suppress','suppression','surrender','susceptible','suspect','suspicion','suspicions','suspicious','suspiciously','swagger','swamped','sweaty','swelled','swelling','swindle','swipe','swollen','symptom','symptoms','syndrome','taboo','tacky','taint','tainted','tamper','tangle','tangled','tangles','tank','tanked','tanks','tantrum','tardy','tarnish','tarnished','tarnishes','tarnishing','tattered','taunt','taunting','tauntingly','taunts','taut','tawdry','taxing','tease','teasingly','tedious','tediously','temerity','temper','tempest','temptation','tenderness','tense','tension','tentative','tentatively','tenuous','tenuously','tepid','terrible','terribleness','terribly','terror','terror-genic','terrorism','terrorize','testily','testy','tetchily','tetchy','thankless','thicker','thirst','thorny','thoughtless','thoughtlessly','thoughtlessness','thrash','threat','threaten','threatening','threats','threesome','throb','throbbed','throbbing','throbs','throttle','thug','thumb-down','thumbs-down','thwart','time-consuming','timid','timidity','timidly','timidness','tin-y','tingled','tingling','tired','tiresome','tiring','tiringly','toil','toll','top-heavy','topple','torment','tormented','torrent','tortuous','torture','tortured','tortures','torturing','torturous','torturously','totalitarian','touchy','toughness','tout','touted','touts','toxic','traduce','tragedy','tragic','tragically','traitor','traitorous','traitorously','tramp','trample','transgress','transgression','trap','traped','trapped','trash','trashed','trashy','trauma','traumatic','traumatically','traumatize','traumatized','travesties','travesty','treacherous','treacherously','treachery','treason','treasonous','trick','tricked','trickery','tricky','trivial','trivialize','trouble','troubled','troublemaker','troubles','troublesome','troublesomely','troubling','troublingly','truant','tumble','tumbled','tumbles','tumultuous','turbulent','turmoil','twist','twisted','twists','two-faced','two-faces','tyrannical','tyrannically','tyranny','tyrant','ugh','uglier','ugliest','ugliness','ugly','ulterior','ultimatum','ultimatums','ultra-hardline','un-viewable','unable','unacceptable','unacceptablely','unacceptably','unaccessible','unaccustomed','unachievable','unaffordable','unappealing','unattractive','unauthentic','unavailable','unavoidably','unbearable','unbearablely','unbelievable','unbelievably','uncaring','uncertain','uncivil','uncivilized','unclean','unclear','uncollectible','uncomfortable','uncomfortably','uncomfy','uncompetitive','uncompromising','uncompromisingly','unconfirmed','unconstitutional','uncontrolled','unconvincing','unconvincingly','uncooperative','uncouth','uncreative','undecided','undefined','undependability','undependable','undercut','undercuts','undercutting','underdog','underestimate','underlings','undermine','undermined','undermines','undermining','underpaid','underpowered','undersized','undesirable','undetermined','undid','undignified','undissolved','undocumented','undone','undue','unease','uneasily','uneasiness','uneasy','uneconomical','unemployed','unequal','unethical','uneven','uneventful','unexpected','unexpectedly','unexplained','unfairly','unfaithful','unfaithfully','unfamiliar','unfavorable','unfeeling','unfinished','unfit','unforeseen','unforgiving','unfortunate','unfortunately','unfounded','unfriendly','unfulfilled','unfunded','ungovernable','ungrateful','unhappily','unhappiness','unhappy','unhealthy','unhelpful','unilateralism','unimaginable','unimaginably','unimportant','uninformed','uninsured','unintelligible','unintelligile','unipolar','unjust','unjustifiable','unjustifiably','unjustified','unjustly','unkind','unkindly','unknown','unlamentable','unlamentably','unlawful','unlawfully','unlawfulness','unleash','unlicensed','unlikely','unlucky','unmoved','unnatural','unnaturally','unnecessary','unneeded','unnerve','unnerved','unnerving','unnervingly','unnoticed','unobserved','unorthodox','unorthodoxy','unpleasant','unpleasantries','unpopular','unpredictable','unprepared','unproductive','unprofitable','unprove','unproved','unproven','unproves','unproving','unqualified','unravel','unraveled','unreachable','unreadable','unrealistic','unreasonable','unreasonably','unrelenting','unrelentingly','unreliability','unreliable','unresolved','unresponsive','unrest','unruly','unsafe','unsatisfactory','unsavory','unscrupulous','unscrupulously','unsecure','unseemly','unsettle','unsettled','unsettling','unsettlingly','unskilled','unsophisticated','unsound','unspeakable','unspeakablely','unspecified','unstable','unsteadily','unsteadiness','unsteady','unsuccessful','unsuccessfully','unsupported','unsupportive','unsure','unsuspecting','unsustainable','untenable','untested','unthinkable','unthinkably','untimely','untouched','untrue','untrustworthy','untruthful','unusable','unusably','unuseable','unuseably','unusual','unusually','unviewable','unwanted','unwarranted','unwatchable','unwelcome','unwell','unwieldy','unwilling','unwillingly','unwillingness','unwise','unwisely','unworkable','unworthy','unyielding','upbraid','upheaval','uprising','uproar','uproarious','uproariously','uproarous','uproarously','uproot','upset','upseting','upsets','upsetting','upsettingly','urgent','useless','usurp','usurper','utterly','vagrant','vague','vagueness','vain','vainly','vanity','vehement','vehemently','vengeance','vengeful','vengefully','vengefulness','venom','venomous','venomously','vent','vestiges','vex','vexation','vexing','vexingly','vibrate','vibrated','vibrates','vibrating','vibration','vice','vicious','viciously','viciousness','victimize','vile','vileness','vilify','villainous','villainously','villains','villian','villianous','villianously','villify','vindictive','vindictively','vindictiveness','violate','violation','violator','violators','violent','violently','viper','virulence','virulent','virulently','virus','vociferous','vociferously','volatile','volatility','vomit','vomited','vomiting','vomits','vulgar','vulnerable','wack','wail','wallow','wane','waning','wanton','war-like','warily','wariness','warlike','warned','warning','warp','warped','wary','washed-out','waste','wasted','wasteful','wastefulness','wasting','water-down','watered-down','wayward','weak','weaken','weakening','weaker','weakness','weaknesses','weariness','wearisome','weary','wedge','weed','weep','weird','weirdly','wheedle','whimper','whine','whining','whiny','whips','whore','whores','wicked','wickedly','wickedness','wild','wildly','wiles','wilt','wily','wimpy','wince','wobble','wobbled','wobbles','woe','woebegone','woeful','woefully','womanizer','womanizing','worn','worried','worriedly','worrier','worries','worrisome','worry','worrying','worryingly','worse','worsen','worsening','worst','worthless','worthlessly','worthlessness','wound','wounds','wrangle','wrath','wreak','wreaked','wreaks','wreck','wrest','wrestle','wretch','wretched','wretchedly','wretchedness','wrinkle','wrinkled','wrinkles','wrip','wripped','wripping','writhe','wrong','wrongful','wrongly','wrought','yawn','zap','zapped','zaps','zealot','zealous','zealously','zombie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features['number_of_positive_words'] = train_test['tweet'].str.lower().apply(lambda x : len(set(re.sub(r'([^\\s\\w]|_)+', '', x).split()) & set(positive_words))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features['number_of_negative_words'] = train_test['tweet'].str.lower().apply(lambda x : len(set(re.sub(r'([^\\s\\w]|_)+', '', x).split()) & set(negative_words))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v0</th>\n",
       "      <th>w2v1</th>\n",
       "      <th>w2v2</th>\n",
       "      <th>w2v3</th>\n",
       "      <th>w2v4</th>\n",
       "      <th>w2v5</th>\n",
       "      <th>w2v6</th>\n",
       "      <th>w2v7</th>\n",
       "      <th>w2v8</th>\n",
       "      <th>w2v9</th>\n",
       "      <th>...</th>\n",
       "      <th>num_of_unique_punctuations</th>\n",
       "      <th>num_of_american_spelling_words</th>\n",
       "      <th>num_of_greatbritain_spelling_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>avg_no_words</th>\n",
       "      <th>num_of_non_english_words</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>number_of_positive_words</th>\n",
       "      <th>number_of_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w2v0      w2v1      w2v2      w2v3      w2v4      w2v5      w2v6  \\\n",
       "0 -0.001281  0.000994  0.007388 -0.000455  0.003235  0.004266  0.002389   \n",
       "1 -0.001831  0.002138  0.005619 -0.001370  0.004186  0.004372  0.002200   \n",
       "2 -0.002518  0.001563  0.006218 -0.002845  0.004764  0.005700 -0.000363   \n",
       "3 -0.002011  0.000873  0.003132  0.000659  0.003971  0.004942  0.001594   \n",
       "4 -0.001778 -0.000013  0.002864  0.000301  0.000116  0.001665  0.000997   \n",
       "\n",
       "       w2v7      w2v8      w2v9            ...             \\\n",
       "0 -0.002703  0.001234  0.000349            ...              \n",
       "1 -0.003409  0.000589  0.001206            ...              \n",
       "2 -0.003761 -0.000141  0.002367            ...              \n",
       "3 -0.003140  0.001512  0.000241            ...              \n",
       "4 -0.001283  0.001022  0.001967            ...              \n",
       "\n",
       "   num_of_unique_punctuations  num_of_american_spelling_words  \\\n",
       "0                           4                               8   \n",
       "1                           6                              10   \n",
       "2                           6                              11   \n",
       "3                           8                              13   \n",
       "4                           4                              22   \n",
       "\n",
       "   num_of_greatbritain_spelling_words  num_stopwords  avg_no_words  \\\n",
       "0                                   8              0     14.000000   \n",
       "1                                  10              3     17.000000   \n",
       "2                                  11              2      5.666667   \n",
       "3                                  13              2     19.000000   \n",
       "4                                  22              8     12.000000   \n",
       "\n",
       "   num_of_non_english_words  textblob_polarity  textblob_subjectivity  \\\n",
       "0                         9           0.675000               1.000000   \n",
       "1                        10           0.233333               0.733333   \n",
       "2                         9           0.625000               0.600000   \n",
       "3                         6           0.375000               1.000000   \n",
       "4                         4          -0.125000               0.950000   \n",
       "\n",
       "   number_of_positive_words  number_of_negative_words  \n",
       "0                         2                         0  \n",
       "1                         1                         0  \n",
       "2                         1                         0  \n",
       "3                         1                         0  \n",
       "4                         2                         1  \n",
       "\n",
       "[5 rows x 319 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features.to_csv('train_test_features_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all=train_test_features[0:len(train.index)]\n",
    "X_test=train_test_features[len(train.index):len(train_test_features.index)]\n",
    "features=list(set(X_train_all.columns) - set('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf29',\n",
       " 'ft6',\n",
       " 'tfidf22',\n",
       " 'tfidf221',\n",
       " 'tfidf163',\n",
       " 'tfidf7',\n",
       " 'tfidf123',\n",
       " \"''\",\n",
       " 'tfidf45',\n",
       " 'tfidf158',\n",
       " 'w2v30',\n",
       " 'w2v23',\n",
       " 'tfidf35',\n",
       " 'tfidf125',\n",
       " 'tfidf179',\n",
       " 'ft0',\n",
       " 'tfidf164',\n",
       " 'ft22',\n",
       " 'tfidf73',\n",
       " 'tfidf118',\n",
       " 'tfidf39',\n",
       " 'tfidf209',\n",
       " 'tfidf92',\n",
       " 'tfidf17',\n",
       " 'tfidf197',\n",
       " 'tfidf198',\n",
       " 'tfidf215',\n",
       " 'WRB',\n",
       " 'w2v19',\n",
       " 'tfidf77',\n",
       " 'tfidf78',\n",
       " 'tfidf154',\n",
       " ',',\n",
       " 'tfidf120',\n",
       " 'tfidf37',\n",
       " 'ft18',\n",
       " 'tfidf66',\n",
       " 'tfidf166',\n",
       " 'tfidf114',\n",
       " 'JJR',\n",
       " 'WP',\n",
       " 'num_of_non_english_words',\n",
       " 'tfidf26',\n",
       " 'ft10',\n",
       " 'ft2',\n",
       " 'tfidf119',\n",
       " 'tfidf142',\n",
       " 'tfidf139',\n",
       " 'tfidf85',\n",
       " 'tfidf56',\n",
       " 'tfidf21',\n",
       " 'w2v2',\n",
       " 'tfidf60',\n",
       " 'tfidf48',\n",
       " 'ft5',\n",
       " 'w2v20',\n",
       " 'tfidf208',\n",
       " 'tfidf75',\n",
       " 'tfidf33',\n",
       " 'ft7',\n",
       " 'tfidf132',\n",
       " 'tfidf220',\n",
       " 'DT',\n",
       " 'tfidf83',\n",
       " 'tfidf155',\n",
       " 'tfidf175',\n",
       " 'ft4',\n",
       " 'tfidf161',\n",
       " 'tfidf145',\n",
       " 'tfidf127',\n",
       " 'tfidf106',\n",
       " 'tfidf147',\n",
       " 'tfidf156',\n",
       " 'tfidf94',\n",
       " 'tfidf143',\n",
       " 'CC',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'CD',\n",
       " 'tfidf159',\n",
       " 'RBS',\n",
       " 'tfidf222',\n",
       " 'tfidf196',\n",
       " 'tfidf188',\n",
       " 'ft21',\n",
       " 'w2v26',\n",
       " 'tfidf227',\n",
       " 'tfidf204',\n",
       " 'w2v38',\n",
       " 'w2v18',\n",
       " 'textblob_polarity',\n",
       " 'tfidf36',\n",
       " 'tfidf211',\n",
       " 'ft32',\n",
       " 'w2v12',\n",
       " 'ft11',\n",
       " 'tfidf101',\n",
       " 'w2v24',\n",
       " 'w2v5',\n",
       " 'tfidf174',\n",
       " 'tfidf141',\n",
       " 'tfidf168',\n",
       " 'UH',\n",
       " 'num_stopwords',\n",
       " 'JJ',\n",
       " 'ft9',\n",
       " 'tfidf130',\n",
       " 'tfidf140',\n",
       " 'tfidf12',\n",
       " 'num_of_unique_punctuations',\n",
       " 'ft31',\n",
       " 'w2v6',\n",
       " 'EX',\n",
       " 'tfidf28',\n",
       " 'tfidf224',\n",
       " 'ft36',\n",
       " '.',\n",
       " 'w2v21',\n",
       " 'tfidf10',\n",
       " 'tfidf110',\n",
       " 'tfidf121',\n",
       " 'w2v37',\n",
       " 'w2v34',\n",
       " 'tfidf151',\n",
       " 'ft37',\n",
       " 'tfidf193',\n",
       " 'tfidf169',\n",
       " 'tfidf108',\n",
       " 'tfidf210',\n",
       " 'tfidf216',\n",
       " 'w2v14',\n",
       " 'w2v25',\n",
       " 'ft17',\n",
       " 'tfidf41',\n",
       " 'tfidf20',\n",
       " 'ft24',\n",
       " 'SYM',\n",
       " 'tfidf103',\n",
       " 'w2v8',\n",
       " 'tfidf136',\n",
       " 'tfidf173',\n",
       " 'tfidf72',\n",
       " 'tfidf111',\n",
       " 'tfidf24',\n",
       " 'VBZ',\n",
       " 'VBD',\n",
       " 'ft12',\n",
       " 'RP',\n",
       " 'tfidf226',\n",
       " 'tfidf124',\n",
       " 'ft15',\n",
       " 'tfidf171',\n",
       " 'tfidf206',\n",
       " 'tfidf146',\n",
       " 'tfidf217',\n",
       " 'tfidf117',\n",
       " 'tfidf129',\n",
       " 'tfidf165',\n",
       " 'tfidf200',\n",
       " 'ft19',\n",
       " 'tfidf194',\n",
       " 'tfidf87',\n",
       " 'tfidf2',\n",
       " 'tfidf184',\n",
       " 'tfidf160',\n",
       " 'tfidf43',\n",
       " 'tfidf212',\n",
       " 'tfidf134',\n",
       " 'tfidf102',\n",
       " 'JJS',\n",
       " 'tfidf138',\n",
       " 'tfidf115',\n",
       " 'w2v10',\n",
       " 'NN',\n",
       " 'tfidf199',\n",
       " 'tfidf49',\n",
       " 'tfidf84',\n",
       " 'tfidf182',\n",
       " '#',\n",
       " 'tfidf148',\n",
       " 'tfidf76',\n",
       " 'tfidf80',\n",
       " 'tfidf47',\n",
       " 'textblob_subjectivity',\n",
       " 'w2v13',\n",
       " 'w2v1',\n",
       " 'tfidf170',\n",
       " 'ft23',\n",
       " 'NNS',\n",
       " 'tfidf98',\n",
       " 'tfidf219',\n",
       " 'tfidf71',\n",
       " 'tfidf46',\n",
       " 'tfidf54',\n",
       " 'tfidf91',\n",
       " 'RBR',\n",
       " 'VBP',\n",
       " 'tfidf25',\n",
       " 'tfidf16',\n",
       " 'tfidf191',\n",
       " 'tfidf1',\n",
       " 'tfidf113',\n",
       " 'ft30',\n",
       " 'tfidf107',\n",
       " 'tfidf3',\n",
       " 'tfidf55',\n",
       " 'tfidf63',\n",
       " 'IN',\n",
       " 'tfidf8',\n",
       " 'tfidf152',\n",
       " 'avg_no_words',\n",
       " 'VBN',\n",
       " 'tfidf205',\n",
       " 'tfidf88',\n",
       " 'tfidf128',\n",
       " 'tfidf207',\n",
       " 'tfidf223',\n",
       " 'tfidf69',\n",
       " 'ft38',\n",
       " 'tfidf105',\n",
       " 'tfidf218',\n",
       " 'VBG',\n",
       " '(',\n",
       " 'tfidf162',\n",
       " 'ft33',\n",
       " 'POS',\n",
       " 'tfidf99',\n",
       " 'w2v9',\n",
       " 'tfidf64',\n",
       " 'tfidf57',\n",
       " 'num_of_greatbritain_spelling_words',\n",
       " 'w2v17',\n",
       " 'tfidf189',\n",
       " 'tfidf137',\n",
       " 'tfidf104',\n",
       " 'tfidf86',\n",
       " '``',\n",
       " 'tfidf203',\n",
       " 'tfidf228',\n",
       " 'tfidf97',\n",
       " 'tfidf150',\n",
       " 'ft39',\n",
       " 'tfidf13',\n",
       " 'tfidf15',\n",
       " 'w2v39',\n",
       " 'w2v0',\n",
       " 'tfidf34',\n",
       " 'tfidf90',\n",
       " '$',\n",
       " 'tfidf32',\n",
       " 'tfidf81',\n",
       " 'ft25',\n",
       " 'ft13',\n",
       " 'w2v3',\n",
       " 'tfidf95',\n",
       " 'ft3',\n",
       " 'tfidf19',\n",
       " 'tfidf59',\n",
       " 'tfidf116',\n",
       " 'tfidf42',\n",
       " 'PDT',\n",
       " 'ft26',\n",
       " 'tfidf126',\n",
       " 'tfidf214',\n",
       " 'w2v29',\n",
       " 'tfidf202',\n",
       " 'ft27',\n",
       " 'tfidf157',\n",
       " 'tfidf82',\n",
       " 'tfidf135',\n",
       " 'number_of_positive_words',\n",
       " 'PRP',\n",
       " 'NNPS',\n",
       " 'tfidf79',\n",
       " 'FW',\n",
       " 'tfidf74',\n",
       " 'tfidf112',\n",
       " 'tfidf0',\n",
       " 'PRP$',\n",
       " 'tfidf5',\n",
       " 'w2v22',\n",
       " 'ft28',\n",
       " 'number_of_negative_words',\n",
       " 'tfidf100',\n",
       " 'tfidf4',\n",
       " 'tfidf30',\n",
       " 'ft16',\n",
       " 'tfidf153',\n",
       " 'TO',\n",
       " 'tfidf96',\n",
       " 'ft20',\n",
       " 'ft1',\n",
       " 'tfidf44',\n",
       " 'tfidf11',\n",
       " 'LS',\n",
       " 'tfidf23',\n",
       " 'tfidf181',\n",
       " 'tfidf172',\n",
       " 'tfidf89',\n",
       " 'num_of_american_spelling_words',\n",
       " 'w2v36',\n",
       " 'w2v7',\n",
       " 'tfidf183',\n",
       " 'tfidf185',\n",
       " 'tfidf177',\n",
       " 'tfidf31',\n",
       " 'tfidf133',\n",
       " 'tfidf144',\n",
       " 'tfidf6',\n",
       " 'tfidf50',\n",
       " 'tfidf70',\n",
       " 'tfidf167',\n",
       " 'tfidf9',\n",
       " 'tfidf68',\n",
       " ')',\n",
       " 'tfidf51',\n",
       " 'w2v15',\n",
       " 'tfidf67',\n",
       " 'WDT',\n",
       " 'tfidf18',\n",
       " 'tfidf225',\n",
       " 'w2v4',\n",
       " 'tfidf186',\n",
       " 'w2v28',\n",
       " 'tfidf201',\n",
       " 'w2v32',\n",
       " 'tfidf62',\n",
       " 'tfidf190',\n",
       " 'tfidf109',\n",
       " 'tfidf61',\n",
       " 'tfidf52',\n",
       " 'tfidf213',\n",
       " 'w2v31',\n",
       " 'w2v35',\n",
       " 'tfidf149',\n",
       " 'w2v11',\n",
       " 'tfidf192',\n",
       " 'VB',\n",
       " 'w2v27',\n",
       " 'tfidf27',\n",
       " 'tfidf176',\n",
       " 'ft29',\n",
       " 'ft8',\n",
       " 'NNP',\n",
       " 'w2v33',\n",
       " 'tfidf122',\n",
       " 'tfidf180',\n",
       " 'tfidf14',\n",
       " 'ft14',\n",
       " 'tfidf93',\n",
       " 'ft35',\n",
       " 'tfidf65',\n",
       " 'ft34',\n",
       " 'tfidf58',\n",
       " 'tfidf131',\n",
       " ':',\n",
       " 'w2v16',\n",
       " 'tfidf178',\n",
       " 'tfidf38',\n",
       " 'tfidf53',\n",
       " 'tfidf195',\n",
       " 'tfidf187',\n",
       " 'tfidf40']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all = X_train_all.reset_index() \n",
    "X_train_all['label'] = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train_all.sample(frac=0.80, replace=False)\n",
    "X_valid=pd.concat([X_train_all, X_train]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 365)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[features],X_train['label'] , missing=np.nan)\n",
    "dvalid = xgb.DMatrix(X_valid[features],missing=np.nan)\n",
    "dtest = xgb.DMatrix(X_test[features], missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.103693\n",
      "[20]\ttrain-error:0.083807\n",
      "[40]\ttrain-error:0.077336\n",
      "[60]\ttrain-error:0.072285\n",
      "[80]\ttrain-error:0.067077\n",
      "[100]\ttrain-error:0.060448\n",
      "[120]\ttrain-error:0.053188\n",
      "[140]\ttrain-error:0.045612\n",
      "[160]\ttrain-error:0.040246\n",
      "[180]\ttrain-error:0.035196\n",
      "[200]\ttrain-error:0.029514\n",
      "[220]\ttrain-error:0.025253\n",
      "[240]\ttrain-error:0.019886\n",
      "[260]\ttrain-error:0.016098\n",
      "[280]\ttrain-error:0.014362\n",
      "[300]\ttrain-error:0.011679\n",
      "[320]\ttrain-error:0.008996\n",
      "[340]\ttrain-error:0.00726\n",
      "[360]\ttrain-error:0.005997\n",
      "[380]\ttrain-error:0.004577\n",
      "[400]\ttrain-error:0.00363\n",
      "[420]\ttrain-error:0.002367\n",
      "[440]\ttrain-error:0.001105\n",
      "[460]\ttrain-error:0.000947\n",
      "[480]\ttrain-error:0.000947\n",
      "[500]\ttrain-error:0.000789\n",
      "[520]\ttrain-error:0.000631\n",
      "[540]\ttrain-error:0.000316\n",
      "[560]\ttrain-error:0.000316\n",
      "[580]\ttrain-error:0.000316\n",
      "[599]\ttrain-error:0\n"
     ]
    }
   ],
   "source": [
    "nrounds = 600\n",
    "watchlist = [(dtrain, 'train')]\n",
    "params = {\"objective\": \"binary:logistic\",\"booster\": \"gbtree\", \"nthread\": 4,\"silent\": 1,\"eta\": 0.05, \"max_depth\": 5, \"subsample\": 0.9, \"colsample_bytree\": 0.7,\"min_child_weight\": 1,\"seed\": 2016, \"tree_method\": \"exact\"}\n",
    "bst = xgb.train(params, dtrain, num_boost_round=nrounds, evals=watchlist, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = bst.predict(dvalid)\n",
    "test_preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_all = xgb.DMatrix(X_train_all[features], missing=np.nan)\n",
    "train_all_preds = bst.predict(dtrain_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id' : train['id'], 'tweet': train['tweet'], 'predicted_probability' : train_all_preds, 'actual_label' : train['label']}).to_csv('train_compare_xgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2616297"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.4659689e-05, 9.1919887e-01, 9.2360002e-01, ..., 9.9521530e-01,\n",
       "       1.5693360e-03, 9.2034556e-02], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.952118\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "fpr, tpr, thresholds = roc_curve(X_valid['label'], valid_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.889365</td>\n",
       "      <td>0.110635</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.23213</td>\n",
       "      <td>0.889952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1-fpr       fpr        tf  thresholds       tpr\n",
       "171  0.889365  0.110635  0.000587     0.23213  0.889952"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# The optimal cut off would be where tpr is high and fpr is low\n",
    "# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "####################################\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf-0).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.997608</td>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.959330</td>\n",
       "      <td>0.986857</td>\n",
       "      <td>0.040670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>-0.958473</td>\n",
       "      <td>0.986450</td>\n",
       "      <td>0.040670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>-0.939334</td>\n",
       "      <td>0.980618</td>\n",
       "      <td>0.059809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998285</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>-0.938476</td>\n",
       "      <td>0.980558</td>\n",
       "      <td>0.059809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1-fpr       fpr        tf  thresholds       tpr\n",
       "0  1.000000  0.000000 -0.997608    0.995745  0.002392\n",
       "1  1.000000  0.000000 -0.959330    0.986857  0.040670\n",
       "2  0.999142  0.000858 -0.958473    0.986450  0.040670\n",
       "3  0.999142  0.000858 -0.939334    0.980618  0.059809\n",
       "4  0.998285  0.001715 -0.938476    0.980558  0.059809"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Receiver operating characteristic')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot tpr vs 1-fpr\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(roc['tpr'])\n",
    "pl.plot(roc['1-fpr'], color = 'red')\n",
    "pl.xlabel('1-False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Receiver operating characteristic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_preds_binary = [1 if i >= 0.23213 else 0 for i in valid_preds]\n",
    "test_preds_binary = [1 if i >= 0.23213 else 0 for i in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891826676349552\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(X_valid['label'], valid_preds_binary, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id' : test['id'], 'label' : test_preds_binary}).to_csv('sub8.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM with Bayesian Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest MSE: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
    "    \n",
    "\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = lgb.LGBMClassifier(objective='binary', boosting_type='gbdt', subsample=0.6143), #colsample_bytree=0.6453, subsample=0.6143\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'num_leaves': (10, 100),      \n",
    "        'max_depth': (0, 50),\n",
    "        'min_child_samples': (0, 50),\n",
    "        'max_bin': (100, 150),\n",
    "        'subsample_freq': (0, 10),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'n_estimators': (50, 100),\n",
    "    },    \n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 1,\n",
    "    n_iter = 100,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best MSE: 0.892\n",
      "Best params: {'learning_rate': 0.06610098295419149, 'max_bin': 136, 'max_depth': 47, 'min_child_samples': 16, 'min_child_weight': 7, 'n_estimators': 71, 'num_leaves': 42, 'subsample_freq': 7}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-36e59e8641ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_cv_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 optim_result = self._step(\n\u001b[1;32m    653\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m                 )\n\u001b[1;32m    656\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             )\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             for train, test in cv_iter)\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "result = bayes_cv_tuner.fit(X_train_all[features], train['label'], callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.6143,\n",
       "        subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_iter=100, n_jobs=1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=42,\n",
       "       refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_log_error',\n",
       "       search_spaces={'learning_rate': (0.01, 1.0, 'log-uniform'), 'num_leaves': (10, 100), 'max_depth': (0, 50), 'min_child_samples': (0, 50), 'max_bin': (100, 150), 'subsample_freq': (0, 10), 'min_child_weight': (0, 10), 'n_estimators': (50, 100)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.71828183, 1.71828183, 1.71828183, ..., 1.71828183, 1.71828183,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bayes_cv_tuner.predict(X_test[features])\n",
    "test_bayes_cv_results = np.expm1(pred)\n",
    "test_bayes_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Deep Learning : Sequential Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 237, 64)           405504    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 417,953\n",
      "Trainable params: 417,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#only works with positive features so use tfidf features and \n",
    "features_dl = ['tfidf' + str(i) for i in range(229)] + ['num_of_unique_punctuations', 'num_of_american_spelling_words', 'num_of_greatbritain_spelling_words', 'num_stopwords', 'avg_no_words', 'num_of_non_english_words', 'number_of_positive_words', 'number_of_negative_words']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(X_train.shape[0], 64,input_length=len(features_dl)))\n",
    "model.add(LSTM(32, dropout=0.4, recurrent_dropout=0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5068 samples, validate on 1268 samples\n",
      "Epoch 1/4\n",
      " - 76s - loss: 0.0868 - acc: 0.7443 - val_loss: 0.0778 - val_acc: 0.7468\n",
      "Epoch 2/4\n",
      " - 75s - loss: 0.0725 - acc: 0.7711 - val_loss: 0.0658 - val_acc: 0.7997\n",
      "Epoch 3/4\n",
      " - 74s - loss: 0.0631 - acc: 0.8114 - val_loss: 0.0623 - val_acc: 0.8013\n",
      "Epoch 4/4\n",
      " - 75s - loss: 0.0575 - acc: 0.8254 - val_loss: 0.0553 - val_acc: 0.8297\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(X_train[features_dl]), X_train['label'], validation_split=0.2 , epochs=4, batch_size=16, verbose=2)\n",
    "results = model.predict(np.array(X_test[features_dl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8700144 ],\n",
       "       [0.25473297],\n",
       "       [0.09240794],\n",
       "       ...,\n",
       "       [0.63608205],\n",
       "       [0.24057639],\n",
       "       [0.16408736]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_results = model.predict(np.array(X_valid[features_dl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.793718</td>\n",
       "      <td>0.206282</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.229931</td>\n",
       "      <td>0.794554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1-fpr       fpr        tf  thresholds       tpr\n",
       "237  0.793718  0.206282  0.000836    0.229931  0.794554"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(X_valid['label'], valid_results)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf-0).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_results_binary = [1 if i >= 0.229931 else 0 for i in valid_preds]\n",
    "test_results_binary = [1 if i >= 0.229931 else 0 for i in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8914092592984503\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(X_valid['label'], valid_results_binary, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id' : test['id'], 'label' : test_results_binary}).to_csv('sub2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Deep Learning : LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "#first parameter i.e. 50 in this case is number of neurons in hidden layer\n",
    "#input_layer_neurons = input_dim = number of columns\n",
    "model.add(Dense(50, input_dim=X_train[features_dl].shape[1], activation='softmax'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='softmax'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 50)                11900     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,901\n",
      "Trainable params: 28,201\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6336 samples, validate on 1582 samples\n",
      "Epoch 1/5\n",
      "6336/6336 [==============================] - 2s 248us/step - loss: 0.0730 - val_loss: 0.0544\n",
      "Epoch 2/5\n",
      "6336/6336 [==============================] - 1s 112us/step - loss: 0.0492 - val_loss: 0.0490\n",
      "Epoch 3/5\n",
      "6336/6336 [==============================] - 1s 106us/step - loss: 0.0456 - val_loss: 0.0466\n",
      "Epoch 4/5\n",
      "6336/6336 [==============================] - 1s 114us/step - loss: 0.0427 - val_loss: 0.0470\n",
      "Epoch 5/5\n",
      "6336/6336 [==============================] - 1s 106us/step - loss: 0.0416 - val_loss: 0.0430\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(X_train[features_dl]), X_train['label'], batch_size=64, \n",
    "          epochs=5, verbose=1, \n",
    "          validation_data=(X_valid[features_dl], X_valid['label']))\n",
    "valid_results_lstm = model.predict(np.array(X_valid[features_dl]))\n",
    "test_results_lstm = model.predict(np.array(X_test[features_dl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_results_lstm_values = pd.DataFrame(valid_results_lstm)[0].values\n",
    "test_results_lstm_values = pd.DataFrame(test_results_lstm)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.871817</td>\n",
       "      <td>0.128183</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>0.341109</td>\n",
       "      <td>0.871287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1-fpr       fpr       tf  thresholds       tpr\n",
       "187  0.871817  0.128183 -0.00053    0.341109  0.871287"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(X_valid['label'], valid_results_lstm_values)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf-0).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_results_lstm_binary = [1 if i >= 0.341109 else 0 for i in valid_results_lstm_values]\n",
    "test_results_lstm_binary = [1 if i >= 0.341109 else 0 for i in test_results_lstm_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8752251492409403\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(X_valid['label'], valid_results_lstm_binary, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id' : test['id'], 'label' : test_results_lstm_binary}).to_csv('sub3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id' : test['id'], 'tweet' : test['tweet'], 'label' : test_results_lstm_binary}).to_csv('compare_understand_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results_lstm = model.predict(np.array(X_train_all[features_dl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results_lstm_values = pd.DataFrame(train_results_lstm)[0].values\n",
    "train_results_lstm_binary = [1 if i >= 0.341109 else 0 for i in train_results_lstm_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id' : train['id'], 'tweet' : train['tweet'], 'label_actual' : train['label'], 'label_obtained' : train_results_lstm_binary, 'predicted_probability' : train_results_lstm_values})\n",
    "df[df['label_actual']!=df['label_obtained']].to_csv('lstm_comparison_training_all_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf of hashtags only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v0</th>\n",
       "      <th>w2v1</th>\n",
       "      <th>w2v2</th>\n",
       "      <th>w2v3</th>\n",
       "      <th>w2v4</th>\n",
       "      <th>w2v5</th>\n",
       "      <th>w2v6</th>\n",
       "      <th>w2v7</th>\n",
       "      <th>w2v8</th>\n",
       "      <th>w2v9</th>\n",
       "      <th>...</th>\n",
       "      <th>JJS</th>\n",
       "      <th>``</th>\n",
       "      <th>''</th>\n",
       "      <th>WDT</th>\n",
       "      <th>UH</th>\n",
       "      <th>(</th>\n",
       "      <th>SYM</th>\n",
       "      <th>LS</th>\n",
       "      <th>FW</th>\n",
       "      <th>RBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002518</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w2v0      w2v1      w2v2      w2v3      w2v4      w2v5      w2v6  \\\n",
       "0 -0.001281  0.000994  0.007388 -0.000455  0.003235  0.004266  0.002389   \n",
       "1 -0.001831  0.002138  0.005619 -0.001370  0.004186  0.004372  0.002200   \n",
       "2 -0.002518  0.001563  0.006218 -0.002845  0.004764  0.005700 -0.000363   \n",
       "3 -0.002011  0.000873  0.003132  0.000659  0.003971  0.004942  0.001594   \n",
       "4 -0.001778 -0.000013  0.002864  0.000301  0.000116  0.001665  0.000997   \n",
       "\n",
       "       w2v7      w2v8      w2v9 ...   JJS  ``  ''  WDT  UH  (  SYM  LS  FW  \\\n",
       "0 -0.002703  0.001234  0.000349 ...     1   1   1    1   1  1    1   1   1   \n",
       "1 -0.003409  0.000589  0.001206 ...     1   1   1    1   1  1    1   1   1   \n",
       "2 -0.003761 -0.000141  0.002367 ...     1   1   1    1   1  1    1   1   1   \n",
       "3 -0.003140  0.001512  0.000241 ...     1   1   1    1   1  1    1   1   1   \n",
       "4 -0.001283  0.001022  0.001967 ...     1   1   1    1   1  1    1   1   1   \n",
       "\n",
       "   RBS  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    1  \n",
       "4    1  \n",
       "\n",
       "[5 rows x 363 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_features.to_csv('train_test_features_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.256740\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(train['label'], X_train_all['textblob_polarity'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.360366</td>\n",
       "      <td>0.639634</td>\n",
       "      <td>-0.052864</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>0.307502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1-fpr       fpr        tf    thresholds       tpr\n",
       "570  0.360366  0.639634 -0.052864  5.551115e-17  0.307502"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf-0).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all=pd.read_csv(\"sub1.csv\")\n",
    "for i in range(2,9):\n",
    "\tdf_all=df_all.append(pd.read_csv(\"sub\"+str(i)+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_ans=df_all.groupby('id',as_index=False)['label'].agg(lambda x: x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_ans.to_csv('sub9_ensemble.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
